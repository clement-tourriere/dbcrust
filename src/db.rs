use crate::config::{SSHTunnelConfig, VerbosityLevel};
use crate::database::{ConnectionInfo, DatabaseClient, DatabaseType, create_database_client};
use crate::database_postgresql::PostgreSQLClient;
use crate::debug_log;
use crate::pgpass;
use crate::ssh_tunnel::{SSHTunnel, SharedSSHTunnel};
use chrono::{DateTime, NaiveDate, NaiveDateTime, NaiveTime, Utc};
use hex;
use serde_json::Value as JsonValue;
use sqlx::postgres::types::{
    Oid as PgOid, PgBox, PgCircle, PgInterval, PgLSeg, PgLine, PgMoney, PgPath, PgPoint, PgPolygon,
    PgTimeTz,
};
use sqlx::postgres::{PgPool, PgPoolOptions, PgRow};
use sqlx::types::ipnetwork::IpNetwork;
use sqlx::types::mac_address::MacAddress;
use sqlx::types::{Decimal, Uuid};
use sqlx::{Column, Executor, Row, Statement, TypeInfo};
use std::collections::HashMap;
use std::error::Error as StdError;

#[derive(Debug)]
pub struct ColumnSelectionAborted;

impl std::fmt::Display for ColumnSelectionAborted {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "Column selection aborted by user")
    }
}

impl StdError for ColumnSelectionAborted {}

/// Connection pool statistics for monitoring and debugging
#[derive(Debug, Clone)]
pub struct PoolStats {
    pub max_connections: u32,
    pub total_connections: u32,
    pub active_connections: u32,
    pub idle_connections: u32,
    pub acquire_timeout_seconds: u64,
}

/// Column filtering metadata to track when results are filtered
#[derive(Debug, Clone)]
pub struct ColumnFilteringInfo {
    pub total_columns: usize,
    pub displayed_columns: usize,
    pub filtered_column_names: Vec<String>,
}

impl ColumnFilteringInfo {
    pub fn new(total_columns: usize, displayed_columns: usize, filtered_column_names: Vec<String>) -> Self {
        Self {
            total_columns,
            displayed_columns,
            filtered_column_names,
        }
    }

    pub fn is_filtered(&self) -> bool {
        self.displayed_columns < self.total_columns
    }
}

/// Query results with optional column filtering information
#[derive(Debug)]
pub struct QueryResultsWithInfo {
    pub data: Vec<Vec<String>>,
    pub column_info: Option<ColumnFilteringInfo>,
}
use std::io::prelude::*;
use std::sync::Arc;
use std::sync::Mutex;
use std::sync::OnceLock;
use std::sync::atomic::AtomicBool;

// Status logging macro that always shows important status messages
macro_rules! status_log {
    ($($arg:tt)*) => {
        println!($($arg)*);
    };
}

// Verbosity-aware logging macro
macro_rules! verbose_log {
    ($verbosity:expr, $min_level:expr, $($arg:tt)*) => {
        match ($verbosity, $min_level) {
            (VerbosityLevel::Quiet, VerbosityLevel::Quiet) |
            (VerbosityLevel::Normal, VerbosityLevel::Quiet) |
            (VerbosityLevel::Normal, VerbosityLevel::Normal) |
            (VerbosityLevel::Verbose, _) => {
                println!($($arg)*);
            }
            _ => {}
        }
    };
}

pub struct Database {
    // New abstraction layer client (will eventually replace PostgreSQL-specific fields)
    database_client: Option<Box<dyn DatabaseClient>>,
    
    // Connection info override for special cases like Vault connections
    connection_info_override: Option<crate::database::ConnectionInfo>,
    
    // Legacy PostgreSQL-specific fields (kept for backward compatibility during migration)
    pool: Option<PgPool>,
    host: String,
    port: u16,
    user: String,
    password: Option<String>, // Password is now an Option<String>
    current_dbname: String,
    expanded_display: bool,
    default_limit: usize,
    autocomplete_enabled: bool,
    explain_mode: bool,
    column_select_mode: bool,
    banner_enabled: bool,
    column_selection_threshold: usize,
    column_views: HashMap<String, Vec<String>>, // Map of column view name -> selected columns
    last_view_key: Option<String>,
    ssh_tunnel: SharedSSHTunnel,
    original_host: String,
    original_port: u16,
    last_json_plan: Option<String>, // Store the last EXPLAIN JSON plan for copying
    // pub shared_runtime: Option<tokio::runtime::Runtime>, // Make shared runtime public
}

impl Database {
    /// Create a new Database instance from a database URL
    pub async fn from_url(
        url: &str,
        default_limit: Option<usize>,
        expanded_display_default: Option<bool>,
    ) -> std::result::Result<Self, Box<dyn StdError>> {
        debug_log!("[Database::from_url] Creating database from URL");
        let step_start = std::time::Instant::now();
        
        // Handle Docker URLs specially
        if url.starts_with("docker://") {
            let (database, _) = Self::from_docker_url(url, default_limit, expanded_display_default).await?;
            return Ok(database);
        }
        
        // Parse the connection info from URL
        let config_start = std::time::Instant::now();
        let config = crate::config::Config::load();
        verbose_log!(config.verbosity_level, VerbosityLevel::Verbose, "  üìã Parsing connection URL...");
        let connection_info = ConnectionInfo::parse_url(url)?;
        debug_log!("[Database::from_url] Parsed URL in {:?}", step_start.elapsed());
        
        // For SQLite, we don't need SSH tunneling
        if connection_info.database_type == DatabaseType::SQLite {
            return Self::from_connection_info(connection_info, default_limit, expanded_display_default, None).await;
        }
        
        // For PostgreSQL/MySQL, check for SSH tunnel patterns
        verbose_log!(config.verbosity_level, VerbosityLevel::Verbose, "  üîç Checking for SSH tunnel patterns...");
        let ssh_tunnel_config = if let Some(ref host) = connection_info.host {
            config.get_ssh_tunnel_for_host(host)
        } else {
            None
        };
        debug_log!("[Database::from_url] Config check took {:?}", config_start.elapsed());
        
        if ssh_tunnel_config.is_some() {
            // SSH tunnel info should always be shown (even in quiet mode)
            verbose_log!(config.verbosity_level, VerbosityLevel::Quiet, "  ‚úì SSH tunnel pattern found for host: {:?}", connection_info.host);
            debug_log!("[Database::from_url] SSH tunnel configuration found for host: {:?}", connection_info.host);
        } else {
            verbose_log!(config.verbosity_level, VerbosityLevel::Verbose, "  ‚ö†Ô∏è  No SSH tunnel pattern found for host: {:?}", connection_info.host);
        }
        
        verbose_log!(config.verbosity_level, VerbosityLevel::Verbose, "  üîß Creating database connection...");
        let conn_start = std::time::Instant::now();
        let result = Self::from_connection_info(connection_info, default_limit, expanded_display_default, ssh_tunnel_config).await;
        debug_log!("[Database::from_url] from_connection_info took {:?}", conn_start.elapsed());
        result
    }
    
    /// Create a new Database instance from a Docker URL
    pub async fn from_docker_url(
        url: &str,
        default_limit: Option<usize>,
        expanded_display_default: Option<bool>,
    ) -> std::result::Result<(Self, Option<ConnectionInfo>), Box<dyn StdError>> {
        debug_log!("[Database::from_docker_url] Creating database from Docker URL");
        
        // Parse Docker URL
        let connection_info = ConnectionInfo::parse_url(url)?;
        
        // Get the container name from the connection info
        let container_name = connection_info.docker_container
            .as_ref()
            .ok_or("Docker container name not found in URL")?;
        
        // If container name is empty, provide interactive selection
        if container_name.is_empty() {
            let selected_container = Self::select_docker_container().await?;
            
            // Create Docker client
            let docker_client = crate::docker::DockerClient::new()
                .map_err(|e| format!("Failed to create Docker client: {e}"))?;
            
            let container_info = docker_client.inspect_container(&selected_container).await
                .map_err(|e| format!("Failed to inspect selected Docker container '{selected_container}': {e}"))?;
            
            // Build database connection info from container
            let docker_connection = docker_client.build_connection_info(&container_info)
                .map_err(|e| format!("Failed to build connection info: {e}"))?;
            
            // Create a new ConnectionInfo with the resolved Docker information
            let resolved_connection_info = ConnectionInfo {
                database_type: docker_connection.database_type,
                host: Some(docker_connection.host),
                port: Some(docker_connection.port),
                username: connection_info.username.filter(|u| !u.is_empty()).or(docker_connection.username),
                password: connection_info.password.filter(|p| !p.is_empty()).or(docker_connection.password),
                database: connection_info.database.or(docker_connection.database_name),
                file_path: None,
                options: connection_info.options,
                docker_container: Some(selected_container.clone()),
            };
            
            let database = Self::from_connection_info(resolved_connection_info.clone(), default_limit, expanded_display_default, None).await?;
            return Ok((database, Some(resolved_connection_info)));
        }
        
        // Create Docker client and inspect the container
        let docker_client = crate::docker::DockerClient::new()
            .map_err(|e| format!("Failed to create Docker client: {e}"))?;
        
        let container_info = docker_client.inspect_container(container_name).await
            .map_err(|e| format!("Failed to inspect Docker container '{container_name}': {e}"))?;
        
        // Build database connection info from container
        let docker_connection = docker_client.build_connection_info(&container_info)
            .map_err(|e| format!("Failed to build connection info: {e}"))?;
        
        // Create a new ConnectionInfo with the resolved Docker information
        let resolved_connection_info = ConnectionInfo {
            database_type: docker_connection.database_type,
            host: Some(docker_connection.host),
            port: Some(docker_connection.port),
            username: connection_info.username.filter(|u| !u.is_empty()).or(docker_connection.username),
            password: connection_info.password.filter(|p| !p.is_empty()).or(docker_connection.password),
            database: connection_info.database.or(docker_connection.database_name),
            file_path: None,
            options: connection_info.options,
            docker_container: Some(container_name.clone()),
        };
        
        debug_log!("[Database::from_docker_url] Resolved Docker connection: {}@{}:{}/{}", 
                  resolved_connection_info.username.as_deref().unwrap_or(""),
                  resolved_connection_info.host.as_deref().unwrap_or(""),
                  resolved_connection_info.port.unwrap_or(0),
                  resolved_connection_info.database.as_deref().unwrap_or(""));
        
        // Create database connection using the resolved info
        let database = Self::from_connection_info(resolved_connection_info.clone(), default_limit, expanded_display_default, None).await?;
        Ok((database, Some(resolved_connection_info)))
    }
    
    /// Interactive Docker container selection
    async fn select_docker_container() -> std::result::Result<String, Box<dyn StdError>> {
        println!("üê≥ Discovering Docker database containers...");
        
        // Create Docker client
        let docker_client = crate::docker::DockerClient::new()
            .map_err(|e| format!("Failed to create Docker client: {e}"))?;
        
        // List all database containers
        let containers = docker_client.list_database_containers().await
            .map_err(|e| format!("Failed to list Docker containers: {e}"))?;
        
        if containers.is_empty() {
            return Err("No database containers found. Make sure you have database containers running.".into());
        }
        
        // Separate running and stopped containers
        let running_containers: Vec<_> = containers.iter()
            .filter(|c| c.status.contains("running") || c.status.contains("Up"))
            .collect();
        let stopped_containers: Vec<_> = containers.iter()
            .filter(|c| !(c.status.contains("running") || c.status.contains("Up")))
            .collect();

        // Show summary of stopped containers if any exist
        if !stopped_containers.is_empty() {
            println!("‚ÑπÔ∏è  Found {} stopped database container(s):", stopped_containers.len());
            for container in &stopped_containers {
                let db_type = container.database_type
                    .as_ref()
                    .map(|dt| format!("{dt}"))
                    .unwrap_or("Unknown".to_string());
                println!("   üî¥ {} ({}) - {}", container.name, db_type, container.status);
            }
            println!();
        }

        // Check if we have any running containers
        if running_containers.is_empty() {
            return Err("No running database containers found. Please start a database container first.".into());
        }

        // Create selection options only for running containers
        let mut options = Vec::new();
        for container in &running_containers {
            let db_type = container.database_type
                .as_ref()
                .map(|dt| format!("{dt}"))
                .unwrap_or("Unknown".to_string());
            
            let port_info = if let Some(port) = container.host_port {
                format!(" | Port: {port}")
            } else {
                " (no exposed port)".to_string()
            };
            
            let option = format!("üü¢ {} ({}) - {}{}", 
                               container.name,
                               db_type,
                               container.status,
                               port_info);
            options.push(option);
        }
        
        // Show interactive selection and get the index
        let selected_index = inquire::Select::new("Select a database container:", options.clone())
            .prompt()
            .map_err(|e| format!("Selection cancelled: {e}"))?;
        
        // Find the index of the selected option
        let container_index = options.iter().position(|option| option == &selected_index)
            .ok_or("Invalid selection")?;
        
        // Get the selected container by index (from running containers only)
        let selected_container = running_containers[container_index];
        
        println!("üì¶ Selected container: {} ({})", 
                selected_container.name,
                selected_container.database_type.as_ref().map(|dt| format!("{dt}")).unwrap_or("Unknown".to_string()));
        
        Ok(selected_container.name.clone())
    }
    
    /// Create a new Database instance from a Docker URL and return connection info for tracking
    pub async fn from_docker_url_with_tracking(
        url: &str,
        default_limit: Option<usize>,
        expanded_display_default: Option<bool>,
    ) -> std::result::Result<(Self, Option<ConnectionInfo>), Box<dyn StdError>> {
        Self::from_docker_url(url, default_limit, expanded_display_default).await
    }
    
    /// Create a new Database instance from ConnectionInfo
    pub async fn from_connection_info(
        connection_info: ConnectionInfo,
        default_limit: Option<usize>,
        expanded_display_default: Option<bool>,
        ssh_tunnel_config: Option<SSHTunnelConfig>,
    ) -> std::result::Result<Self, Box<dyn StdError>> {
        debug_log!("[Database::from_connection_info] Creating database from connection info");
        
        let config_start = std::time::Instant::now();
        let config = crate::config::Config::load();
        verbose_log!(config.verbosity_level, VerbosityLevel::Verbose, "    üì¶ Loading configuration...");
        debug_log!("[Database::from_connection_info] Config loaded in {:?}", config_start.elapsed());
        
        // Create database client using the new abstraction layer
        // Skip this for SSH tunnel scenarios to avoid premature connection attempts
        verbose_log!(config.verbosity_level, VerbosityLevel::Verbose, "    üîå Creating database client...");
        let client_start = std::time::Instant::now();
        let database_client = if ssh_tunnel_config.is_some() {
            // Skip database client creation for SSH tunnel scenarios - use legacy path
            verbose_log!(config.verbosity_level, VerbosityLevel::Verbose, "    ‚è≠Ô∏è  Skipping database client for SSH tunnel scenario");
            None
        } else {
            match create_database_client(connection_info.clone()).await {
                Ok(client) => Some(client),
                Err(e) => {
                    debug_log!("Failed to create database client: {}. Will use legacy implementation if available.", e);
                    // For SQLite databases, we must use the new abstraction layer - don't allow fallback to mock
                    if connection_info.database_type == DatabaseType::SQLite {
                        return Err(format!("Failed to create SQLite database client: {e}").into());
                    }
                    None
                }
            }
        };
        debug_log!("[Database::from_connection_info] Database client creation took {:?}", client_start.elapsed());
        
        // For non-PostgreSQL databases, we don't use the legacy fields
        let (pool, host, port, user, password, current_dbname, ssh_tunnel, original_host, original_port) = 
            if connection_info.database_type == DatabaseType::PostgreSQL {
                // Use legacy PostgreSQL implementation as fallback
                let host = connection_info.host.unwrap_or_else(|| "localhost".to_string());
                let port = connection_info.port.unwrap_or(5432);
                let user = connection_info.username.unwrap_or_else(|| "postgres".to_string());
                let dbname = connection_info.database.unwrap_or_else(|| "postgres".to_string());
                
                // Store original connection details
                let original_host = host.clone();
                let original_port = port;
                
                // Create SSH tunnel if configured
                let ssh_tunnel = Arc::new(Mutex::new(SSHTunnel::new()));
                
                // Variable to store the pool once created (either directly or after SSH tunnel)
                let mut pg_pool: Option<sqlx::PgPool> = None;
                
                // Determine the actual host and port to use for database connection
                let (connect_host, connect_port) = if let Some(ref tunnel_config) = ssh_tunnel_config {
                    if tunnel_config.enabled {
                        let mut tunnel_guard = ssh_tunnel.lock().unwrap();
                        
                        // Ensure there's a tunnel instance
                        if tunnel_guard.is_none() {
                            *tunnel_guard = SSHTunnel::new();
                        }
                        
                        // Establish the tunnel
                        if let Some(ref mut actual_tunnel) = *tunnel_guard {
                            match actual_tunnel.establish(tunnel_config, &host, port).await {
                                Ok(local_port) => {
                                    status_log!(
                                        "SSH tunnel: {}:{} via {}@{} -> 127.0.0.1:{}",
                                        host,
                                        port,
                                        tunnel_config.ssh_username.as_ref().unwrap_or(&"unknown".to_string()),
                                        tunnel_config.ssh_host,
                                        local_port
                                    );
                                    
                                    // Now create the PostgreSQL pool using the tunnel connection
                                    // SSH tunnel info should always be shown
                                    verbose_log!(config.verbosity_level, VerbosityLevel::Quiet, "    üîå Creating PostgreSQL pool through SSH tunnel...");
                                    let tunnel_connect_options = sqlx::postgres::PgConnectOptions::new()
                                        .host("127.0.0.1")
                                        .port(local_port)
                                        .username(&user)
                                        .database(&dbname);
                                    
                                    let tunnel_connect_options = if let Some(ref pass) = connection_info.password {
                                        tunnel_connect_options.password(pass)
                                    } else {
                                        tunnel_connect_options
                                    };
                                    
                                    // Create the pool now that tunnel is established
                                    pg_pool = Some(sqlx::postgres::PgPoolOptions::new()
                                        .max_connections(10)
                                        .min_connections(0)
                                        .acquire_timeout(std::time::Duration::from_secs(15))
                                        .idle_timeout(std::time::Duration::from_secs(60))
                                        .max_lifetime(std::time::Duration::from_secs(1800))
                                        .test_before_acquire(false)
                                        .connect_with(tunnel_connect_options)
                                        .await
                                        .map_err(|e| format!("Failed to create PostgreSQL pool through SSH tunnel: {e}"))?);
                                    
                                    // Release the tunnel guard
                                    drop(tunnel_guard);
                                    
                                    ("127.0.0.1".to_string(), local_port)
                                },
                                Err(e) => {
                                    return Err(format!("Failed to establish SSH tunnel: {e}").into());
                                }
                            }
                        } else {
                            return Err("Failed to create SSH tunnel instance".into());
                        }
                    } else {
                        (host.clone(), port)
                    }
                } else {
                    (host.clone(), port)
                };
                
                // Create PostgreSQL connection with actual connection details
                let mut connect_options = sqlx::postgres::PgConnectOptions::new()
                    .host(&connect_host)
                    .port(connect_port)
                    .username(&user)
                    .database(&dbname);

                if let Some(ref pass) = connection_info.password {
                    connect_options = connect_options.password(pass);
                }

                // Create pool if not already created through SSH tunnel
                if pg_pool.is_none() {
                    verbose_log!(config.verbosity_level, VerbosityLevel::Verbose, "    üîå Creating PostgreSQL pool...");
                    pg_pool = Some(sqlx::postgres::PgPoolOptions::new()
                        .max_connections(10) // Increased pool size for autocompletion with large databases
                        .min_connections(0) // Don't pre-connect
                        .acquire_timeout(std::time::Duration::from_secs(15))
                        .idle_timeout(std::time::Duration::from_secs(60))
                        .max_lifetime(std::time::Duration::from_secs(1800))
                        .test_before_acquire(false)
                        .connect_with(connect_options)
                        .await?);
                }
                
                (pg_pool, connect_host, connect_port, user.clone(), connection_info.password.clone(), 
                 dbname.clone(), ssh_tunnel, original_host, original_port)
            } else {
                // For SQLite and other databases, use appropriate values (SSH tunneling not applicable)
                let _ = ssh_tunnel_config; // Acknowledge the parameter to avoid warning
                
                // Set appropriate values based on database type
                let (host, port, user, current_db) = match connection_info.database_type {
                    DatabaseType::SQLite => {
                        let db_name = connection_info.file_path
                            .as_ref()
                            .and_then(|path| std::path::Path::new(path).file_stem())
                            .and_then(|stem| stem.to_str())
                            .unwrap_or("main")
                            .to_string();
                        ("localhost".to_string(), 5432, "sqlite_user".to_string(), db_name)
                    },
                    DatabaseType::MySQL => {
                        let host = connection_info.host.unwrap_or_else(|| "localhost".to_string());
                        let port = connection_info.port.unwrap_or(3306);
                        let user = connection_info.username.unwrap_or_else(|| "root".to_string());
                        let db_name = connection_info.database.unwrap_or_else(|| "mysql".to_string());
                        (host, port, user, db_name)
                    },
                    _ => {
                        ("localhost".to_string(), 5432, "user".to_string(), "main".to_string())
                    }
                };
                
                (None, host, port, user, None, 
                 current_db, Arc::new(Mutex::new(SSHTunnel::new())), "localhost".to_string(), 5432)
            };

        let db = Self {
            database_client,
            connection_info_override: None,
            pool,
            host,
            port,
            user,
            password,
            current_dbname,
            expanded_display: expanded_display_default.unwrap_or(false),
            default_limit: default_limit.unwrap_or(10),
            autocomplete_enabled: config.autocomplete_enabled,
            explain_mode: config.explain_mode_default,
            column_select_mode: false,
            banner_enabled: config.show_banner,
            column_selection_threshold: config.column_selection_threshold,
            column_views: HashMap::new(),
            last_view_key: None,
            ssh_tunnel,
            original_host,
            original_port,
            last_json_plan: None,
        };

        // Validate the connection before returning
        debug_log!("[Database::from_connection_info] Validating connection");
        db.validate_connection().await?;

        Ok(db)
    }

    pub async fn new(
        host: &str,
        port: u16,
        user: &str,
        password_param: &str,
        dbname: &str,
        default_limit: Option<usize>,
        expanded_display_default: Option<bool>,
        ssh_tunnel_config: Option<SSHTunnelConfig>,
        ssl_mode: Option<sqlx::postgres::PgSslMode>,
    ) -> std::result::Result<Self, Box<dyn StdError>> {
        let password = if password_param.is_empty() {
            pgpass::lookup_password(host, port, dbname, user)
        } else {
            Some(password_param.to_string())
        };

        let config = crate::config::Config::load();

        // Store the original connection details
        let original_host = host.to_string();
        let original_port = port;

        // Create a new SSH tunnel if configured
        let ssh_tunnel = Arc::new(Mutex::new(SSHTunnel::new()));

        // Create a shared runtime for metadata queries
        /*
        let shared_runtime = Some(
            tokio::runtime::Builder::new_current_thread()
                .enable_all()
                .build()
                .unwrap_or_else(|e| {
                    eprintln!("Failed to build shared runtime: {}", e);
                    tokio::runtime::Builder::new_current_thread()
                        .enable_time()
                        .build()
                        .expect("Failed to build minimal runtime")
                }),
        );
        */

        // Determine the actual host and port to use for the database connection
        let (connect_host, connect_port) = if let Some(ref tunnel_config) = ssh_tunnel_config {
            if tunnel_config.enabled {
                let mut tunnel_guard = ssh_tunnel.lock().unwrap();

                // Ensure there's a tunnel instance. If not, create one.
                if tunnel_guard.is_none() {
                    *tunnel_guard = SSHTunnel::new(); // SSHTunnel::new() returns Option<SSHTunnel>
                }

                // Now, tunnel_guard definitely holds Some(SSHTunnel), so we can proceed.
                if let Some(ref mut actual_tunnel_instance) = *tunnel_guard {
                    match actual_tunnel_instance
                        .establish(tunnel_config, host, port)
                        .await
                    {
                        Ok(local_port) => {
                            // Show essential SSH tunnel information
                            status_log!(
                                "SSH tunnel: {}:{} via {}@{} -> 127.0.0.1:{}",
                                host,
                                port,
                                tunnel_config
                                    .ssh_username
                                    .as_ref()
                                    .unwrap_or(&"<no-user>".to_string()),
                                tunnel_config.ssh_host,
                                local_port
                            );

                            // Use localhost and the assigned local port for the actual connection
                            ("127.0.0.1".to_string(), local_port)
                        }
                        Err(e) => {
                            return Err(format!("Failed to establish SSH tunnel: {e}").into());
                        }
                    }
                } else {
                    // This path should ideally not be reached if SSHTunnel::new() is successful.
                    return Err(
                        "Failed to initialize SSH tunnel instance for establishment.".into(),
                    );
                }
            } else {
                (host.to_string(), port)
            }
        } else {
            (host.to_string(), port)
        };

        let mut connect_options = sqlx::postgres::PgConnectOptions::new()
            .host(&connect_host)
            .port(connect_port)
            .username(user)
            .database(dbname);

        if let Some(ref pass) = password {
            connect_options = connect_options.password(pass);
        }

        if let Some(ssl_mode) = ssl_mode {
            connect_options = connect_options.ssl_mode(ssl_mode);
        }

        // Configure connection pool with SSH tunnel optimizations
        let use_ssh_optimizations = ssh_tunnel_config.is_some();

        let pool_options = if use_ssh_optimizations {
            PgPoolOptions::new()
                .max_connections(8) // Optimized for SSH tunnel autocompletion (reduced from 10 to prevent connection exhaustion)
                .min_connections(3) // Keep more connections alive for SSH tunnels to avoid connection overhead
                .acquire_timeout(std::time::Duration::from_secs(15)) // Longer timeout for SSH connection acquisition
                .idle_timeout(std::time::Duration::from_secs(300)) // Keep connections alive for 5 minutes (longer for SSH)
                .max_lifetime(std::time::Duration::from_secs(1800)) // 30-minute connection lifetime for SSH stability
                .test_before_acquire(false) // Skip connection validation for better SSH performance
        } else {
            PgPoolOptions::new()
                .max_connections(10) // Increased pool size for autocompletion with large databases
                .min_connections(2) // Keep some connections alive
                .acquire_timeout(std::time::Duration::from_secs(2)) // Reduced to 2s for faster SSH tunnel setup
                .idle_timeout(std::time::Duration::from_secs(60)) // Shorter idle timeout for direct connections
                .max_lifetime(std::time::Duration::from_secs(1800)) // 30-minute connection lifetime
                .test_before_acquire(false) // Skip connection validation for better performance
        };

        // Try to establish connection with better error reporting
        debug_log!(
            "Attempting to connect to database at {}:{}",
            connect_host,
            connect_port
        );
        debug_log!(
            "Connection options: user={}, database={}, ssl_mode={:?}",
            user,
            dbname,
            ssl_mode
        );

        // Skip test connection and go directly to pool creation for debugging

        let pool = pool_options.connect_with(connect_options).await?;

        // Pre-warm the connection pool for SSH tunnels to improve first query performance
        if use_ssh_optimizations {
            Self::warm_up_connection_pool(&pool).await?;
        }

        // Create PostgreSQL client using the new abstraction layer
        let mut options = std::collections::HashMap::new();
        if let Some(ssl_mode) = ssl_mode {
            let ssl_mode_str = match ssl_mode {
                sqlx::postgres::PgSslMode::Disable => "disable",
                sqlx::postgres::PgSslMode::Allow => "allow", 
                sqlx::postgres::PgSslMode::Prefer => "prefer",
                sqlx::postgres::PgSslMode::Require => "require",
                sqlx::postgres::PgSslMode::VerifyCa => "verify-ca",
                sqlx::postgres::PgSslMode::VerifyFull => "verify-full",
            };
            options.insert("sslmode".to_string(), ssl_mode_str.to_string());
        }

        let connection_info = ConnectionInfo {
            database_type: DatabaseType::PostgreSQL,
            host: Some(connect_host.clone()),
            port: Some(connect_port),
            username: Some(user.to_string()),
            password: password.clone(),
            database: Some(dbname.to_string()),
            file_path: None,
            options,
            docker_container: None,
        };

        // Create the database client (allow failure for now during migration)
        let database_client = match PostgreSQLClient::new(connection_info).await {
            Ok(client) => Some(Box::new(client) as Box<dyn DatabaseClient>),
            Err(e) => {
                debug_log!("Failed to create PostgreSQL client: {}. Using legacy PostgreSQL implementation.", e);
                None
            }
        };

        let mut db = Self {
            database_client,
            connection_info_override: None,
            pool: Some(pool),
            host: connect_host,
            port: connect_port,
            user: user.to_string(),
            password,
            current_dbname: dbname.to_string(),
            expanded_display: expanded_display_default.unwrap_or(false),
            default_limit: default_limit.unwrap_or(10),
            autocomplete_enabled: config.autocomplete_enabled,
            explain_mode: config.explain_mode_default,
            column_select_mode: false,
            banner_enabled: config.show_banner,
            column_selection_threshold: config.column_selection_threshold,
            column_views: HashMap::new(),
            last_view_key: None,
            ssh_tunnel,
            original_host,
            original_port,
            last_json_plan: None,
            // shared_runtime,
        };

        // Pre-cache metadata for SSH tunnels to improve autocompletion performance
        if use_ssh_optimizations {
            let _ = db.prefetch_metadata_async().await; // Ignore errors in prefetch
        }

        // Validate the connection before returning
        debug_log!("[Database::new] Validating connection");
        db.validate_connection().await?;

        Ok(db)
    }

    /// Warm up the connection pool by establishing initial connections
    async fn warm_up_connection_pool(pool: &PgPool) -> std::result::Result<(), Box<dyn StdError>> {
        // Execute a simple query to establish connections
        let _ = sqlx::query("SELECT 1").fetch_one(pool).await?;
        debug_log!("Connection pool warmed up successfully");
        Ok(())
    }

    /// Prefetch metadata asynchronously to warm up autocompletion cache
    async fn prefetch_metadata_async(&mut self) -> std::result::Result<(), Box<dyn StdError>> {
        if let Some(pool) = &self.pool {
            debug_log!("Starting metadata prefetch for autocompletion");

            // Execute all metadata queries in parallel using optimized pg_catalog queries
            let schemas_future = sqlx::query(
                r#"
                SELECT nspname as schema_name
                FROM pg_namespace
                WHERE nspname NOT LIKE 'pg_%' 
                  AND nspname NOT IN ('information_schema', 'pg_toast')
                ORDER BY nspname
                "#,
            )
            .fetch_all(pool);

            let tables_future = sqlx::query(
                r#"
                SELECT c.relname as table_name, n.nspname as table_schema
                FROM pg_class c
                INNER JOIN pg_namespace n ON c.relnamespace = n.oid
                WHERE c.relkind IN ('r', 'v', 'm', 'f', 'p')  -- tables, views, materialized views, foreign tables, partitioned tables
                  AND n.nspname NOT LIKE 'pg_%'
                  AND n.nspname NOT IN ('information_schema', 'pg_toast')
                ORDER BY n.nspname, c.relname
                "#,
            ).fetch_all(pool);

            // Execute queries concurrently
            let (schemas_result, tables_result) = tokio::try_join!(schemas_future, tables_future)?;

            debug_log!(
                "Metadata prefetch completed: {} schemas, {} tables",
                schemas_result.len(),
                tables_result.len()
            );
        }
        Ok(())
    }

    pub async fn connect_to_db(
        &mut self,
        dbname: &str,
    ) -> std::result::Result<(), Box<dyn StdError>> {
        if self.pool.is_none() && cfg!(test) {
            // Allow connect_to_db to "succeed" in test mode for certain tests
            self.current_dbname = dbname.to_string();
            return Ok(());
        }

        // Try using the new database abstraction layer first
        if let Some(ref mut database_client) = self.database_client {
            debug_log!("Using new database abstraction layer for connect_to_db");
            match database_client.connect_to_database(dbname).await {
                Ok(()) => {
                    // Update the stored database name
                    self.current_dbname = dbname.to_string();
                    debug_log!("Successfully switched to database '{}' using database client", dbname);
                    return Ok(());
                }
                Err(e) => {
                    debug_log!("Database client connect_to_database failed: {}. Falling back to legacy implementation.", e);
                    // For non-PostgreSQL databases, return the error instead of falling back
                    if database_client.get_connection_info().database_type != crate::database::DatabaseType::PostgreSQL {
                        return Err(Box::new(e));
                    }
                    // Fall through to legacy implementation for PostgreSQL
                }
            }
        }

        // Fallback to legacy PostgreSQL implementation
        debug_log!("Using legacy PostgreSQL implementation for connect_to_db");

        let password_to_use =
            if self.password.is_none() || self.password.as_ref().is_none_or(|p| p.is_empty()) {
                pgpass::lookup_password(&self.original_host, self.original_port, dbname, &self.user)
            } else {
                self.password.clone()
            };

        // Close the old pool before creating a new one
        if let Some(p) = self.pool.as_mut() {
            p.close().await;
        }

        let mut connect_options = sqlx::postgres::PgConnectOptions::new()
            .host(&self.host)
            .port(self.port)
            .username(&self.user)
            .database(dbname);

        if let Some(ref pass) = password_to_use {
            connect_options = connect_options.password(pass);
        }

        // Use consistent pool settings with the main connection
        let new_pool = PgPoolOptions::new()
            .max_connections(10) // Increased pool size for autocompletion with large databases
            .min_connections(2) // Keep some connections alive
            .acquire_timeout(std::time::Duration::from_secs(2))  // Reduced to 2s for faster SSH tunnel setup
            .idle_timeout(std::time::Duration::from_secs(60))
            .max_lifetime(std::time::Duration::from_secs(1800))
            .test_before_acquire(false)
            .connect_with(connect_options)
            .await?;

        self.pool = Some(new_pool); // Assign new pool

        self.current_dbname = dbname.to_string();
        self.password = password_to_use; // Update stored password if it was fetched from pgpass
        Ok(())
    }

    pub async fn list_databases(
        &mut self,
    ) -> std::result::Result<Vec<Vec<String>>, Box<dyn StdError>> {
        // Try using the new database abstraction layer first
        if let Some(ref database_client) = self.database_client {
            debug_log!("Using new database abstraction layer for list_databases");
            match database_client.list_databases().await {
                Ok(results) => return Ok(results),
                Err(e) => {
                    debug_log!("Database client list_databases failed: {}. Falling back to legacy implementation.", e);
                }
            }
        }

        // Fallback to legacy implementation
        debug_log!("Using legacy PostgreSQL implementation for list_databases");
        
        if self.pool.is_none() {
            // Mock implementation for tests
            return Ok(vec![
                vec![
                    "Name".to_string(),
                    "Owner".to_string(),
                    "Encoding".to_string(),
                    "Collate".to_string(),
                    "Size".to_string(),
                ],
                vec![
                    "test_db1".to_string(),
                    "test_owner".to_string(),
                    "UTF8".to_string(),
                    "C".to_string(),
                    "10 MB".to_string(),
                ],
                vec![
                    "test_db2".to_string(),
                    "test_owner".to_string(),
                    "UTF8".to_string(),
                    "C".to_string(),
                    "20 MB".to_string(),
                ],
            ]);
        }

        let pool = self.pool.as_ref().ok_or("Database pool not initialized")?;
        let query = r#"
            SELECT 
                d.datname AS "Name",
                pg_get_userbyid(d.datdba) AS "Owner",
                pg_encoding_to_char(d.encoding) AS "Encoding",
                CASE WHEN d.datcollate = d.datctype THEN d.datcollate ELSE d.datcollate || '/' || d.datctype END AS "Collate",
                pg_size_pretty(pg_database_size(d.datname)) AS "Size"
            FROM 
                pg_database d
            WHERE 
                d.datistemplate = false
            ORDER BY 
                d.datname
        "#;

        // Add timeout to metadata query to prevent hanging
        let timeout_duration = std::time::Duration::from_secs(self.get_metadata_timeout());
        let rows = match tokio::time::timeout(
            timeout_duration,
            sqlx::query(query).fetch_all(pool)
        ).await {
            Ok(Ok(rows)) => rows,
            Ok(Err(e)) => return Err(e.into()),
            Err(_) => return Err(format!("Metadata query timed out after {} seconds", self.get_metadata_timeout()).into()),
        };

        if rows.is_empty() {
            return Ok(vec![vec![
                "Name".to_string(),
                "Owner".to_string(),
                "Encoding".to_string(),
                "Collate".to_string(),
                "Size".to_string(),
            ]]);
        }

        let mut results = Vec::new();

        // Add header row
        results.push(vec![
            "Name".to_string(),
            "Owner".to_string(),
            "Encoding".to_string(),
            "Collate".to_string(),
            "Size".to_string(),
        ]);

        // Add data rows
        for row in rows {
            let name: Option<String> = row.try_get(0).ok();
            let owner: Option<String> = row.try_get(1).ok();
            let encoding: Option<String> = row.try_get(2).ok();
            let collate: Option<String> = row.try_get(3).ok();
            let size: Option<String> = row.try_get(4).ok();

            results.push(vec![
                name.unwrap_or_default(),
                owner.unwrap_or_default(),
                encoding.unwrap_or_default(),
                collate.unwrap_or_default(),
                size.unwrap_or_default(),
            ]);
        }

        Ok(results)
    }

    /// List users (database-specific implementation)
    pub async fn list_users(&mut self) -> std::result::Result<Vec<Vec<String>>, Box<dyn StdError>> {
        debug_log!("[Database::list_users] Listing database users");
        
        // Try using the new database abstraction layer first
        if let Some(ref database_client) = self.database_client {
            debug_log!("Using database abstraction layer for list_users");
            
            let connection_info = database_client.get_connection_info();
            
            match connection_info.database_type {
                crate::database::DatabaseType::MySQL => {
                    match self.execute_query("SELECT User, Host, account_locked FROM mysql.user ORDER BY User").await {
                        Ok(results) => return Ok(results),
                        Err(e) => {
                            debug_log!("MySQL user query failed: {}", e);
                            return Err(format!("Error listing MySQL users: {e}").into());
                        }
                    }
                },
                crate::database::DatabaseType::SQLite => {
                    // SQLite doesn't have users concept
                    return Ok(vec![
                        vec!["Note".to_string()],
                        vec!["SQLite is file-based and doesn't have user accounts".to_string()],
                        vec!["Access control is handled at the file system level".to_string()],
                    ]);
                },
                crate::database::DatabaseType::PostgreSQL => {
                    // Fall through to PostgreSQL implementation below
                }
            }
        }
        
        // PostgreSQL implementation (legacy)
        if self.pool.is_none() {
            return Ok(vec![
                vec!["Username".to_string(), "Superuser".to_string(), "Create DB".to_string()],
                vec!["test_user".to_string(), "false".to_string(), "true".to_string()],
            ]);
        }
        
        let _pool = self.pool.as_ref().ok_or("Database pool not initialized")?;
        match self.execute_query("SELECT usename, usesuper, usecreatedb FROM pg_user ORDER BY usename").await {
            Ok(results) => Ok(results),
            Err(e) => Err(format!("Error listing PostgreSQL users: {e}").into()),
        }
    }

    /// List indexes (primarily for SQLite)
    pub async fn list_indexes(&mut self) -> std::result::Result<Vec<Vec<String>>, Box<dyn StdError>> {
        debug_log!("[Database::list_indexes] Listing database indexes");
        
        // Try using the new database abstraction layer first
        if let Some(ref database_client) = self.database_client {
            debug_log!("Using database abstraction layer for list_indexes");
            
            let connection_info = database_client.get_connection_info();
            
            match connection_info.database_type {
                crate::database::DatabaseType::SQLite => {
                    let query = r#"
                        SELECT 
                            name as 'Index Name',
                            tbl_name as 'Table',
                            CASE 
                                WHEN "unique" = 1 THEN 'UNIQUE'
                                ELSE 'NON-UNIQUE'
                            END as 'Type'
                        FROM sqlite_master 
                        WHERE type = 'index' 
                          AND name NOT LIKE 'sqlite_%'
                        ORDER BY tbl_name, name
                    "#;
                    match self.execute_query(query).await {
                        Ok(results) => return Ok(results),
                        Err(e) => return Err(format!("Error listing SQLite indexes: {e}").into()),
                    }
                },
                crate::database::DatabaseType::MySQL => {
                    return Ok(vec![
                        vec!["Note".to_string()],
                        vec!["Use MySQL's SHOW INDEX FROM <table> command".to_string()],
                        vec!["Or query INFORMATION_SCHEMA.STATISTICS".to_string()],
                    ]);
                },
                crate::database::DatabaseType::PostgreSQL => {
                    return Ok(vec![
                        vec!["Note".to_string()],
                        vec!["Use PostgreSQL's \\di command or".to_string()],
                        vec!["Query pg_indexes system view".to_string()],
                    ]);
                }
            }
        }
        
        // Default response for when database abstraction layer is not available
        Ok(vec![
            vec!["Note".to_string()],
            vec!["Index listing not available for this database type".to_string()],
        ])
    }

    /// List pragmas (SQLite-specific)
    pub async fn list_pragmas(&mut self) -> std::result::Result<Vec<Vec<String>>, Box<dyn StdError>> {
        debug_log!("[Database::list_pragmas] Listing database pragmas");
        
        // Try using the new database abstraction layer first
        if let Some(ref database_client) = self.database_client {
            debug_log!("Using database abstraction layer for list_pragmas");
            
            let connection_info = database_client.get_connection_info();
            
            match connection_info.database_type {
                crate::database::DatabaseType::SQLite => {
                    // Get common SQLite pragma values
                    let mut results = Vec::new();
                    results.push(vec!["Pragma".to_string(), "Value".to_string()]);
                    
                    let pragmas = vec![
                        "PRAGMA journal_mode",
                        "PRAGMA synchronous", 
                        "PRAGMA cache_size",
                        "PRAGMA foreign_keys",
                        "PRAGMA auto_vacuum",
                        "PRAGMA encoding",
                        "PRAGMA page_size",
                        "PRAGMA temp_store",
                        "PRAGMA locking_mode",
                        "PRAGMA wal_autocheckpoint",
                    ];
                    
                    for pragma in pragmas {
                        match self.execute_query(pragma).await {
                            Ok(pragma_results) => {
                                if pragma_results.len() > 1 && !pragma_results[1].is_empty() {
                                    let pragma_name = pragma.replace("PRAGMA ", "");
                                    let value = &pragma_results[1][0];
                                    results.push(vec![pragma_name, value.clone()]);
                                }
                            },
                            Err(_) => {
                                // Skip pragmas that fail
                            }
                        }
                    }
                    
                    return Ok(results);
                },
                _ => {
                    return Ok(vec![
                        vec!["Note".to_string()],
                        vec!["Pragmas are specific to SQLite".to_string()],
                        vec!["This command is only available for SQLite databases".to_string()],
                    ]);
                }
            }
        }
        
        // Default response
        Ok(vec![
            vec!["Note".to_string()],
            vec!["Pragma listing not available for this database type".to_string()],
        ])
    }

    pub fn get_current_db(&self) -> String {
        self.current_dbname.clone()
    }

    pub fn get_username(&self) -> &str {
        &self.user
    }

    pub fn get_host(&self) -> &str {
        &self.host
    }

    pub fn get_port(&self) -> u16 {
        self.port
    }

    pub fn get_pool(&self) -> Option<&PgPool> {
        self.pool.as_ref()
    }

    /// Get connection pool statistics for monitoring and debugging
    pub fn get_pool_stats(&self) -> Option<PoolStats> {
        if let Some(pool) = &self.pool {
            let idle = pool.num_idle() as u32;
            let total = pool.size() as u32;
            let active = total - idle;
            
            Some(PoolStats {
                max_connections: pool.options().get_max_connections(),
                idle_connections: idle,
                active_connections: active,
                total_connections: total,
                acquire_timeout_seconds: pool.options().get_acquire_timeout().as_secs(),
            })
        } else {
            None
        }
    }

    /// Log detailed connection pool information for debugging
    pub fn log_pool_stats(&self, context: &str) {
        if let Some(stats) = self.get_pool_stats() {
            debug_log!(
                "[{}] Pool Stats - Total: {}, Active: {}, Idle: {}, Max: {}, Timeout: {}s",
                context,
                stats.total_connections,
                stats.active_connections,
                stats.idle_connections,
                stats.max_connections,
                stats.acquire_timeout_seconds
            );
        } else {
            debug_log!("[{}] No pool available for stats", context);
        }
    }

    /// Check if the connection pool is healthy (not exhausted)
    pub fn is_pool_healthy(&self) -> bool {
        if let Some(stats) = self.get_pool_stats() {
            // Consider pool healthy if we have less than 80% active connections
            let utilization_ratio = stats.active_connections as f64 / stats.max_connections as f64;
            utilization_ratio < 0.8
        } else {
            false // No pool = not healthy
        }
    }

    pub fn get_database_client(&self) -> Option<&Box<dyn DatabaseClient>> {
        self.database_client.as_ref()
    }
    
    /// Check if we have a valid database connection (either new client or legacy pool)
    /// This is used by completion system to determine if metadata queries are possible
    pub fn has_database_connection(&self) -> bool {
        self.database_client.is_some() || self.pool.is_some()
    }
    
    /// Check if this is a test database instance (used by completion system for mock data)
    /// This is separate from has_database_connection to cleanly separate test vs production logic
    pub fn is_test_instance(&self) -> bool {
        // Test instances are created with specific test markers
        self.host == "localhost_test" && self.user == "testuser_mock"
    }
    
    /// Get the current connection information
    pub fn get_connection_info(&self) -> Option<&crate::database::ConnectionInfo> {
        // Check override first (for Vault connections), then fall back to database client
        if let Some(ref override_info) = self.connection_info_override {
            Some(override_info)
        } else {
            self.database_client.as_ref().map(|client| client.get_connection_info())
        }
    }

    /// Set or override the connection information for this database
    /// This is useful for cases like Vault connections where the connection info
    /// needs to be set after database creation
    pub fn set_connection_info_override(&mut self, connection_info: crate::database::ConnectionInfo) {
        self.connection_info_override = Some(connection_info);
    }

    pub async fn list_tables(
        &mut self,
    ) -> std::result::Result<Vec<Vec<String>>, Box<dyn StdError>> {
        // Use the new database abstraction layer if available
        if let Some(ref database_client) = self.database_client {
            match database_client.get_metadata_provider().get_tables(None).await {
                Ok(tables) => {
                    let mut results = Vec::new();
                    // Add header row
                    results.push(vec![
                        "Schema".to_string(),
                        "Name".to_string(),
                        "Type".to_string(),
                        "Owner".to_string(),
                    ]);
                    
                    // Add table rows
                    let default_schema = database_client
                        .get_metadata_provider()
                        .default_schema()
                        .unwrap_or_else(|| "main".to_string());
                    
                    for table in tables {
                        results.push(vec![
                            default_schema.clone(),
                            table,
                            "table".to_string(),
                            self.get_username().to_string(),
                        ]);
                    }
                    
                    return Ok(results);
                }
                Err(e) => {
                    debug_log!("Error using database client for list_tables: {}", e);
                    // Fall through to legacy implementation
                }
            }
        }
        
        if self.pool.is_none() {
            // Mock implementation for tests
            return Ok(vec![
                vec![
                    "Schema".to_string(),
                    "Name".to_string(),
                    "Type".to_string(),
                    "Owner".to_string(),
                ],
                vec![
                    "public".to_string(),
                    "users".to_string(),
                    "table".to_string(),
                    "testuser_mock".to_string(),
                ],
                vec![
                    "public".to_string(),
                    "orders".to_string(),
                    "table".to_string(),
                    "testuser_mock".to_string(),
                ],
                vec![
                    "custom_schema".to_string(),
                    "custom_table1".to_string(),
                    "table".to_string(),
                    "testuser_mock".to_string(),
                ],
            ]);
        }
        let pool_ref = self
            .pool
            .as_ref()
            .ok_or_else(|| Box::<dyn StdError>::from("Database pool not initialized"))?;
        let query = r#"
            SELECT 
                table_schema AS "Schema",
                table_name AS "Name",
                CASE 
                    WHEN table_type = 'BASE TABLE' THEN 'table'
                    WHEN table_type = 'VIEW' THEN 'view'
                    ELSE lower(table_type)
                END AS "Type",
                pg_get_userbyid(relowner) AS "Owner"
            FROM 
                information_schema.tables t
            JOIN 
                pg_class c ON c.relname = t.table_name AND c.relnamespace = (SELECT oid FROM pg_namespace WHERE nspname = t.table_schema)
            WHERE 
                table_schema NOT IN ('pg_catalog', 'information_schema')
            UNION
            SELECT 
                n.nspname AS "Schema",
                c.relname AS "Name",
                'sequence' AS "Type",
                pg_get_userbyid(c.relowner) AS "Owner"
            FROM 
                pg_class c
            JOIN 
                pg_namespace n ON n.oid = c.relnamespace
            WHERE 
                c.relkind = 'S' AND n.nspname NOT IN ('pg_catalog', 'information_schema')
            ORDER BY 
                "Schema", "Name"
        "#;

        let rows = sqlx::query(query).fetch_all(pool_ref).await?; // Use pool_ref

        if rows.is_empty() {
            return Ok(vec![vec![
                "Schema".to_string(),
                "Name".to_string(),
                "Type".to_string(),
                "Owner".to_string(),
            ]]);
        }

        let mut results = Vec::new();

        // Add header row
        results.push(vec![
            "Schema".to_string(),
            "Name".to_string(),
            "Type".to_string(),
            "Owner".to_string(),
        ]);

        // Add data rows
        for row in rows {
            let schema: Option<String> = row.try_get(0).ok();
            let name: Option<String> = row.try_get(1).ok();
            let type_str: Option<String> = row.try_get(2).ok();
            let owner: Option<String> = row.try_get(3).ok();

            results.push(vec![
                schema.unwrap_or_default(),
                name.unwrap_or_default(),
                type_str.unwrap_or_default(),
                owner.unwrap_or_default(),
            ]);
        }

        Ok(results)
    }

    pub async fn execute_query(
        &mut self,
        query: &str,
    ) -> std::result::Result<Vec<Vec<String>>, Box<dyn StdError>> {
        self.execute_query_with_interrupt(query, &std::sync::Arc::new(std::sync::atomic::AtomicBool::new(false))).await
    }

    pub async fn execute_query_with_info(
        &mut self,
        query: &str,
    ) -> std::result::Result<QueryResultsWithInfo, Box<dyn StdError>> {
        self.execute_query_with_interrupt_and_info(query, &std::sync::Arc::new(std::sync::atomic::AtomicBool::new(false))).await
    }

    pub async fn execute_query_with_interrupt(
        &mut self,
        query: &str,
        interrupt_flag: &std::sync::Arc<std::sync::atomic::AtomicBool>,
    ) -> std::result::Result<Vec<Vec<String>>, Box<dyn StdError>> {
        // Use the new method that returns metadata and extract just the data
        match self.execute_query_with_interrupt_and_info(query, interrupt_flag).await {
            Ok(results_with_info) => Ok(results_with_info.data),
            Err(e) => Err(e),
        }
    }

    pub async fn execute_query_with_interrupt_and_info(
        &mut self,
        query: &str,
        interrupt_flag: &std::sync::Arc<std::sync::atomic::AtomicBool>,
    ) -> std::result::Result<QueryResultsWithInfo, Box<dyn StdError>> {
        // Check if we should EXPLAIN this query (applies to all database types)
        if self.explain_mode && is_query_explainable(query) {
            debug_log!("EXPLAIN mode is enabled, executing EXPLAIN query");
            let results = self.execute_explain_query(query).await?;
            return Ok(QueryResultsWithInfo {
                data: results,
                column_info: None,
            });
        }
        
        // Try using the new database abstraction layer first
        if let Some(ref database_client) = self.database_client {
            debug_log!("Using new database abstraction layer for execute_query");
            match database_client.execute_query(query).await {
                Ok(results) => return self.apply_column_selection_if_needed_with_info(results, interrupt_flag),
                Err(e) => {
                    debug_log!("Database client execute_query failed: {}. Falling back to legacy implementation.", e);
                    // For non-PostgreSQL databases, return the error instead of falling back
                    if database_client.get_connection_info().database_type != crate::database::DatabaseType::PostgreSQL {
                        return Err(Box::new(e));
                    }
                    // Fall through to legacy implementation for PostgreSQL
                }
            }
        }

        // Fallback to legacy implementation
        debug_log!("Using legacy PostgreSQL implementation for execute_query");
        
        if self.pool.is_none() {
            // Mock response for execute_query
            if query.to_lowercase().contains("select * from users") {
                let results = vec![
                    vec!["id".to_string(), "name".to_string(), "email".to_string()],
                    vec![
                        "1".to_string(),
                        "Alice".to_string(),
                        "alice@example.com".to_string(),
                    ],
                    vec![
                        "2".to_string(),
                        "Bob".to_string(),
                        "bob@example.com".to_string(),
                    ],
                ];
                return self.apply_column_selection_if_needed_with_info(results, interrupt_flag);
            } else if query.to_lowercase().contains("select * from orders") {
                let results = vec![
                    vec![
                        "order_id".to_string(),
                        "item_name".to_string(),
                        "quantity".to_string(),
                    ],
                    vec!["101".to_string(), "Laptop".to_string(), "1".to_string()],
                ];
                return self.apply_column_selection_if_needed_with_info(results, interrupt_flag);
            }
            // Default mock for other queries, e.g. DDL or unknown SELECTs
            return Ok(QueryResultsWithInfo {
                data: vec![vec!["Mocked_execute_query_success".to_string()]],
                column_info: None,
            });
        }

        let pool_ref = self.pool.as_ref().ok_or_else(|| {
            Box::<dyn StdError>::from("Database pool not initialized for execute_query")
        })?;

        let query_with_limit = self.maybe_add_limit(query);

        // Add timeout to query execution to prevent hanging
        let timeout_duration = std::time::Duration::from_secs(self.get_query_timeout());
        let fetched_rows: Vec<PgRow> = match tokio::time::timeout(
            timeout_duration,
            sqlx::query(&query_with_limit).fetch_all(pool_ref)
        ).await {
            Ok(Ok(rows)) => rows,
            Ok(Err(e)) => return Err(e.into()),
            Err(_) => return Err(format!("Query timed out after {} seconds", self.get_query_timeout()).into()),
        };

        if fetched_rows.is_empty() {
            // To get headers for an empty result set, we need to prepare and inspect columns
            // This is a bit more involved with sqlx compared to postgres crate's direct statement.columns()
            // We can try to describe the query, but this is not always robust for all query types.
            // A simpler approach for now is to return an empty Vec if there are no rows,
            // or potentially try to get column info from a PREPARE statement if really needed.
            // For now, returning Ok(vec![]) if no rows.
            // If the original query was something like `CREATE TABLE` or `INSERT` without returning, it might not have columns.
            // We can try preparing to get column names.
            match pool_ref.prepare(&query_with_limit).await {
                // Use pool_ref
                Ok(prepared_query) => {
                    let column_names: Vec<String> = prepared_query
                        .columns()
                        .iter()
                        .map(|c| c.name().to_string())
                        .collect();
                    if column_names.is_empty() {
                        Ok(QueryResultsWithInfo {
                            data: vec![],
                            column_info: None,
                        }) // No columns, e.g., for DDL like CREATE TABLE
                    } else {
                        Ok(QueryResultsWithInfo {
                            data: vec![column_names],
                            column_info: None,
                        }) // Only header if result set is empty
                    }
                }
                Err(_) => {
                    // If prepare fails (e.g. for some types of statements that can't be prepared or have syntax errors)
                    // or if the query itself was a non-SELECT that affects 0 rows and returns nothing.
                    Ok(QueryResultsWithInfo {
                        data: vec![],
                        column_info: None,
                    })
                }
            }
        } else {
            let mut results: Vec<Vec<String>> = Vec::new();

            // Extract column names from the first row (all rows have the same columns)
            let column_names: Vec<String> = fetched_rows[0]
                .columns()
                .iter()
                .map(|c| c.name().to_string())
                .collect();
            results.push(column_names.clone()); // Header row

            for row in fetched_rows {
                let mut data_row: Vec<String> = Vec::new();
                for (i, column) in column_names.iter().enumerate() {
                    let type_info = row.column(i).type_info();
                    let value_str = match type_info.name() {
                        "BOOL" => row.try_get::<Option<bool>, _>(i).map(|v| v.map_or("NULL".to_string(), |b| b.to_string())),
                        "BYTEA" => row.try_get::<Option<Vec<u8>>, _>(i).map(|v| v.map_or("NULL".to_string(), hex::encode)),
 
                        "INT2" => row.try_get::<Option<i16>, _>(i).map(|v| v.map_or("NULL".to_string(), |val| val.to_string())),
                        "INT4" => row.try_get::<Option<i32>, _>(i).map(|v| v.map_or("NULL".to_string(), |val| val.to_string())),
                        "INT8" => row.try_get::<Option<i64>, _>(i).map(|v| v.map_or("NULL".to_string(), |val| val.to_string())),
                        "OID" => row.try_get::<Option<PgOid>, _>(i).map(|v| v.map_or("NULL".to_string(), |oid_val| oid_val.0.to_string())), // Use PgOid and access its inner u32
                        "FLOAT4" => row.try_get::<Option<f32>, _>(i).map(|v| v.map_or("NULL".to_string(), |val| val.to_string())),
                        "FLOAT8" => row.try_get::<Option<f64>, _>(i).map(|v| v.map_or("NULL".to_string(), |val| val.to_string())),
                        "TEXT" | "VARCHAR" | "NAME" | "BPCHAR" | "CHAR" | "UNKNOWN" => row.try_get::<Option<String>, _>(i).map(|v| v.unwrap_or_else(|| "NULL".to_string())),
                        "XML" => row.try_get::<Option<String>, _>(i).map(|v| v.unwrap_or_else(|| "NULL".to_string())), 
                        "TIMESTAMP" => row.try_get::<Option<NaiveDateTime>, _>(i).map(|v| v.map_or("NULL".to_string(), |dt| dt.to_string())),
                        "TIMESTAMPTZ" => row.try_get::<Option<DateTime<Utc>>, _>(i).map(|v| v.map_or("NULL".to_string(), |dt| dt.to_string())),
                        "DATE" => row.try_get::<Option<NaiveDate>, _>(i).map(|v| v.map_or("NULL".to_string(), |d| d.to_string())),
                        "TIME" => row.try_get::<Option<NaiveTime>, _>(i).map(|v| v.map_or("NULL".to_string(), |t| t.to_string())),
                        "TIMETZ" => row.try_get::<Option<PgTimeTz>, _>(i).map(|v| v.map_or("NULL".to_string(), |t| format!("{t:?}"))), // Use Debug format for PgTimeTz
                        "JSON" | "JSONB" => row.try_get::<Option<JsonValue>, _>(i).map(|v| v.map_or("NULL".to_string(), |j| j.to_string())),
                        "UUID" => row.try_get::<Option<Uuid>, _>(i).map(|v| v.map_or("NULL".to_string(), |u| u.to_string())),
                        "INET" | "CIDR" => row.try_get::<Option<IpNetwork>, _>(i).map(|v| v.map_or("NULL".to_string(), |ip| ip.to_string())),
                        "MACADDR" => row.try_get::<Option<MacAddress>, _>(i).map(|v| v.map_or("NULL".to_string(), |mac| mac.to_string())),
                        "INTERVAL" => row.try_get::<Option<PgInterval>, _>(i).map(|v| v.map_or("NULL".to_string(), |val| format_pg_interval_simple(&val))),
                        "MONEY" => row.try_get::<Option<PgMoney>, _>(i).map(|v| v.map_or("NULL".to_string(), |val| format_pg_money(&val))),
                        "NUMERIC" => row.try_get::<Option<Decimal>, _>(i).map(|v| v.map_or("NULL".to_string(), |d| d.to_string())), 
                        // Geometric types - use Debug formatting
                        "POINT" => row.try_get::<Option<PgPoint>, _>(i).map(|v| v.map_or("NULL".to_string(), |p| format!("{p:?}"))),
                        "LINE" => row.try_get::<Option<PgLine>, _>(i).map(|v| v.map_or("NULL".to_string(), |l| format!("{l:?}"))),
                        "LSEG" => row.try_get::<Option<PgLSeg>, _>(i).map(|v| v.map_or("NULL".to_string(), |ls| format!("{ls:?}"))),
                        "BOX" => row.try_get::<Option<PgBox>, _>(i).map(|v| v.map_or("NULL".to_string(), |b| format!("{b:?}"))),
                        "PATH" => row.try_get::<Option<PgPath>, _>(i).map(|v| v.map_or("NULL".to_string(), |p| format!("{p:?}"))),
                        "POLYGON" => row.try_get::<Option<PgPolygon>, _>(i).map(|v| v.map_or("NULL".to_string(), |p| format!("{p:?}"))),
                        "CIRCLE" => row.try_get::<Option<PgCircle>, _>(i).map(|v| v.map_or("NULL".to_string(), |c| format!("{c:?}"))),
                        // Text Search Types - specialized handling
                        "TSVECTOR" | "tsvector" => {
                            // Just return a placeholder and log the issue to a file instead of console
                            log_type_error(&format!(
                                "Info: tsvector type encountered in column {column} (idx: {i}). Using placeholder."
                            ));
                            // Always return a simple placeholder without attempting to decode
                            Ok("[TSVECTOR]".to_string())
                        },
                        "TSQUERY" | "tsquery" => {
                            // Just return a placeholder and log the issue to a file instead of console
                            log_type_error(&format!(
                                "Info: tsquery type encountered in column {column} (idx: {i}). Using placeholder."
                            ));
                            // Always return a simple placeholder without attempting to decode
                            Ok("[TSQUERY]".to_string())
                        },
                        // Array types need specific handling
                        "_BOOL" => row.try_get::<Option<Vec<bool>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| e.to_string()).collect::<Vec<_>>().join(",")))),
                        "_BYTEA" => row.try_get::<Option<Vec<Vec<u8>>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(hex::encode).collect::<Vec<_>>().join(",")))),
                        "_CHAR" => row.try_get::<Option<Vec<String>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|s| format!("\"{}\"", s.replace("\"", "\\\""))).collect::<Vec<_>>().join(",")))),
                        "_INT2" => row.try_get::<Option<Vec<i16>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| e.to_string()).collect::<Vec<_>>().join(",")))),
                        "_INT4" => row.try_get::<Option<Vec<i32>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| e.to_string()).collect::<Vec<_>>().join(",")))),
                        "_INT8" => row.try_get::<Option<Vec<i64>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| e.to_string()).collect::<Vec<_>>().join(",")))),
                        "_OID" => row.try_get::<Option<Vec<PgOid>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|oid_val| oid_val.0.to_string()).collect::<Vec<_>>().join(",")))), // Use PgOid
                        "_FLOAT4" => row.try_get::<Option<Vec<f32>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| e.to_string()).collect::<Vec<_>>().join(",")))),
                        "_FLOAT8" => row.try_get::<Option<Vec<f64>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| e.to_string()).collect::<Vec<_>>().join(",")))),
                        "_TEXT" | "_VARCHAR" | "_NAME" | "_BPCHAR" => row.try_get::<Option<Vec<String>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|s| format!("\"{}\"", s.replace("\"", "\\\""))).collect::<Vec<_>>().join(",")))),
                        "_XML" => row.try_get::<Option<Vec<String>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|s| format!("\"{}\"", s.replace("\"", "\\\""))).collect::<Vec<_>>().join(",")))),
                        "_TIMESTAMP" => row.try_get::<Option<Vec<NaiveDateTime>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| e.to_string()).collect::<Vec<_>>().join(",")))),
                        "_TIMESTAMPTZ" => row.try_get::<Option<Vec<DateTime<Utc>>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| e.to_string()).collect::<Vec<_>>().join(",")))),
                        "_DATE" => row.try_get::<Option<Vec<NaiveDate>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| e.to_string()).collect::<Vec<_>>().join(",")))),
                        "_TIME" => row.try_get::<Option<Vec<NaiveTime>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| e.to_string()).collect::<Vec<_>>().join(",")))),
                        "_TIMETZ" => row.try_get::<Option<Vec<PgTimeTz>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| format!("{e:?}")).collect::<Vec<_>>().join(",")))), // Use Debug format
                        "_JSON" | "_JSONB" => row.try_get::<Option<Vec<JsonValue>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| e.to_string()).collect::<Vec<_>>().join(",")))),
                        "_UUID" => row.try_get::<Option<Vec<Uuid>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| e.to_string()).collect::<Vec<_>>().join(",")))),
                        "_INET" | "_CIDR" => row.try_get::<Option<Vec<IpNetwork>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| e.to_string()).collect::<Vec<_>>().join(",")))),
                        "_MACADDR" => row.try_get::<Option<Vec<MacAddress>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| e.to_string()).collect::<Vec<_>>().join(",")))),
                        "_INTERVAL" => row.try_get::<Option<Vec<PgInterval>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(format_pg_interval_simple).collect::<Vec<_>>().join(",")))),
                        "_MONEY" => row.try_get::<Option<Vec<PgMoney>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(format_pg_money).collect::<Vec<_>>().join(",")))),
                        "_NUMERIC" => row.try_get::<Option<Vec<Decimal>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| e.to_string()).collect::<Vec<_>>().join(",")))),
                        // Geometric array types - use Debug formatting
                        "_POINT" => row.try_get::<Option<Vec<PgPoint>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| format!("{e:?}")).collect::<Vec<_>>().join(",")))),
                        "_LINE" => row.try_get::<Option<Vec<PgLine>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| format!("{e:?}")).collect::<Vec<_>>().join(",")))),
                        "_LSEG" => row.try_get::<Option<Vec<PgLSeg>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| format!("{e:?}")).collect::<Vec<_>>().join(",")))),
                        "_BOX" => row.try_get::<Option<Vec<PgBox>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| format!("{e:?}")).collect::<Vec<_>>().join(",")))),
                        "_PATH" => row.try_get::<Option<Vec<PgPath>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| format!("{e:?}")).collect::<Vec<_>>().join(",")))),
                        "_POLYGON" => row.try_get::<Option<Vec<PgPolygon>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| format!("{e:?}")).collect::<Vec<_>>().join(",")))),
                        "_CIRCLE" => row.try_get::<Option<Vec<PgCircle>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| format!("{e:?}")).collect::<Vec<_>>().join(",")))),
                        // Text Search array types - commented out
                        // "_TSVECTOR" => row.try_get::<Option<Vec<PgTsVector>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| e.to_string()).collect::<Vec<_>>().join(",")))),
                        // "_TSQUERY" => row.try_get::<Option<Vec<PgTsQuery>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|e| e.to_string()).collect::<Vec<_>>().join(",")))),
                        "_BIT" | "_VARBIT" => row.try_get::<Option<Vec<String>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|s| format!("\"{}\"", s.replace("\"", "\\\""))).collect::<Vec<_>>().join(",")))),
                        // Special case for TEXT[] which comes directly from PostgreSQL
                        "TEXT[]" => row.try_get::<Option<Vec<String>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|s| format!("\"{}\"", s.replace("\"", "\\\""))).collect::<Vec<_>>().join(",")))),

                        // Fallback for other/unknown types, including other array types not explicitly handled
                        type_name if type_name.starts_with('_') || type_name.ends_with("[]") => {
                            // Attempt to treat as Vec<String> for generic array display
                            eprintln!("Warning: Unhandled array type '{type_name}'. Attempting to display as Vec<String>.");
                            row.try_get::<Option<Vec<String>>, _>(i).map(|v| v.map_or("NULL".to_string(), |arr| format!("{{{}}}", arr.iter().map(|s| format!("\"{}\"", s.replace("\"", "\\\""))).collect::<Vec<_>>().join(","))))
                        },
                        other_type => {
                            // Log to file instead of console
                            log_type_error(&format!(
                                "Warning: Unhandled scalar type '{other_type}' in column {column} (idx: {i}). Attempting string fallback."
                            ));
                            // Attempt to fallback to string representation
                            row.try_get::<Option<String>, _>(i).map(|v| v.unwrap_or_else(|| "NULL".to_string()))
                        }
                    }.unwrap_or_else(|e| {
                        // Log errors to file instead of console
                        log_type_error(&format!(
                            "Error decoding column '{}' (type {}): {}. Using placeholder.", 
                            column, type_info.name(), e
                        ));
                        // Return a clean placeholder instead of ERR
                        format!("[{}]", type_info.name())
                    });
                    data_row.push(value_str);
                }
                results.push(data_row);
            }
            // Apply column selection if needed
            self.apply_column_selection_if_needed_with_info(results, interrupt_flag)
        }
    }
    
    /// Apply column selection based on threshold or cs mode
    pub fn apply_column_selection_if_needed(
        &mut self,
        results: Vec<Vec<String>>,
        interrupt_flag: &std::sync::Arc<std::sync::atomic::AtomicBool>,
    ) -> std::result::Result<Vec<Vec<String>>, Box<dyn StdError>> {
        // Use the new method that returns metadata and extract just the data
        match self.apply_column_selection_if_needed_with_info(results, interrupt_flag) {
            Ok(results_with_info) => Ok(results_with_info.data),
            Err(e) => Err(e),
        }
    }

    /// Apply column selection based on threshold or cs mode, returning metadata
    pub fn apply_column_selection_if_needed_with_info(
        &mut self,
        results: Vec<Vec<String>>,
        interrupt_flag: &std::sync::Arc<std::sync::atomic::AtomicBool>,
    ) -> std::result::Result<QueryResultsWithInfo, Box<dyn StdError>> {
        // Don't apply column selection if results are empty or only contain header
        if results.len() <= 1 {
            return Ok(QueryResultsWithInfo {
                data: results,
                column_info: None,
            });
        }
        
        let column_count = results[0].len();
        
        // Check if we should apply column selection
        let should_apply = self.column_select_mode || self.should_auto_enable_column_selection(column_count);
        
        if should_apply {
            debug_log!("Applying column selection: cs_mode={}, columns={}, threshold={}", 
                      self.column_select_mode, column_count, self.column_selection_threshold);
            match self.interactive_column_selection_with_info(&results, interrupt_flag) {
                Ok(results_with_info) => Ok(results_with_info),
                Err(e) if e.is::<ColumnSelectionAborted>() => {
                    // Re-throw the abort error to propagate it up
                    Err(e)
                }
                Err(e) => {
                    // For other errors, log and return original results
                    eprintln!("Column selection error: {}", e);
                    Ok(QueryResultsWithInfo {
                        data: results,
                        column_info: None,
                    })
                }
            }
        } else {
            Ok(QueryResultsWithInfo {
                data: results,
                column_info: None,
            })
        }
    }

    pub fn is_expanded_display(&self) -> bool {
        self.expanded_display
    }

    pub fn toggle_expanded_display(&mut self) -> bool {
        self.expanded_display = !self.expanded_display;
        self.expanded_display
    }

    // New helper method to add a LIMIT clause to SELECT queries if not already present
    fn maybe_add_limit(&self, query: &str) -> String {
        // Remove trailing semicolon for processing purposes
        let cleaned_query = query.trim().trim_end_matches(';');
        let trimmed = cleaned_query.to_ascii_lowercase();

        // Only process SELECT queries
        if !trimmed.starts_with("select") {
            return query.to_string();
        }

        // Don't add LIMIT if it already exists
        if trimmed.contains(" limit ") {
            return query.to_string();
        }

        // Check for LIMIT in subqueries by manually scanning the string
        let mut in_parentheses = 0;
        for (i, c) in trimmed.chars().enumerate() {
            match c {
                '(' => in_parentheses += 1,
                ')' => {
                    if in_parentheses > 0 {
                        in_parentheses -= 1;
                    }
                }
                'l' if in_parentheses == 0
                    && i + 5 < trimmed.len()
                    && &trimmed[i..i + 6] == "limit " =>
                {
                    // Found LIMIT outside of parentheses
                    return query.to_string();
                }
                _ => {}
            }
        }

        // If the original query had a semicolon, add LIMIT before it
        if query.trim().ends_with(';') {
            // Extract the last character (semicolon)
            let query_without_semicolon = query.trim_end().trim_end_matches(';');
            format!("{} LIMIT {};", query_without_semicolon, self.default_limit)
        } else {
            // Append the LIMIT clause
            format!("{} LIMIT {}", query, self.default_limit)
        }
    }

    /// Validates a query by attempting to prepare it without executing
    pub async fn validate_query(
        &mut self,
        query: &str,
    ) -> std::result::Result<(), Box<dyn StdError>> {
        if self.pool.is_none() {
            // Mock implementation: assume all queries are valid in test mode
            return Ok(());
        }
        let pool_ref = self.pool.as_ref().ok_or_else(|| {
            Box::<dyn StdError>::from("Database pool not initialized for validate_query")
        })?;
        // For simplicity, we'll assume standard $n placeholders or no placeholders.
        // If complex non-standard placeholders are used, this validation might be insufficient.
        pool_ref.prepare(query).await?; // Use pool_ref
        Ok(())
    }

    pub fn is_autocomplete(&self) -> bool {
        self.autocomplete_enabled
    }

    pub fn set_autocomplete(&mut self, enabled: bool) {
        self.autocomplete_enabled = enabled;
    }

    pub fn is_explain_mode(&self) -> bool {
        self.explain_mode
    }

    pub fn toggle_explain_mode(&mut self) -> bool {
        self.explain_mode = !self.explain_mode;
        self.explain_mode
    }

    /// Execute a query with raw EXPLAIN output (no formatting)
    pub async fn execute_explain_query_raw(
        &mut self,
        query: &str,
    ) -> std::result::Result<Vec<Vec<String>>, Box<dyn StdError>> {
        debug_log!("[execute_explain_query_raw] Executing raw EXPLAIN query");
        
        // Try using the new database abstraction layer first
        if let Some(ref database_client) = self.database_client {
            debug_log!("[execute_explain_query_raw] Using database abstraction layer for raw EXPLAIN");
            match database_client.explain_query_raw(query).await {
                Ok(results) => {
                    debug_log!("[execute_explain_query_raw] Database abstraction layer returned {} rows", results.len());
                    
                    // Store the JSON plan for copying (for PostgreSQL and MySQL)
                    match database_client.get_connection_info().database_type {
                        crate::database::DatabaseType::PostgreSQL => {
                            if results.len() > 1 && !results[1].is_empty() {
                                // Store the JSON plan from the second row (first row is header)
                                self.last_json_plan = Some(results[1][0].clone());
                            }
                        }
                        crate::database::DatabaseType::MySQL => {
                            if results.len() > 1 && !results[1].is_empty() {
                                // Store the JSON plan from the second row (first row is header)
                                self.last_json_plan = Some(results[1][0].clone());
                            }
                        }
                        _ => {
                            // SQLite doesn't use JSON explain plans
                        }
                    }
                    
                    return Ok(results);
                },
                Err(e) => {
                    debug_log!("[execute_explain_query_raw] Database abstraction layer failed: {}", e);
                    return Err(Box::new(e));
                }
            }
        }

        // Legacy PostgreSQL implementation fallback
        debug_log!("[execute_explain_query_raw] Using legacy PostgreSQL implementation");
        
        if self.pool.is_none() {
            return Ok(vec![
                vec!["QUERY PLAN".to_string()],
                vec!["Raw Explain Output".to_string()],
            ]);
        }
        let pool_ref = self.pool.as_ref().ok_or_else(|| {
            Box::<dyn StdError>::from("Database pool not initialized for execute_explain_query_raw")
        })?;

        let explain_query = format!("EXPLAIN (FORMAT JSON) {query}");
        let explain_results: Vec<JsonValue> = sqlx::query_scalar(&explain_query)
            .fetch_all(pool_ref)
            .await?;

        let mut output_table = vec![vec!["Raw EXPLAIN Output".to_string()]];
        for plan_json in &explain_results {
            output_table.push(vec![plan_json.to_string()]);
        }
        
        // Store the JSON plan for copying (first plan if multiple)
        if !explain_results.is_empty() {
            self.last_json_plan = Some(explain_results[0].to_string());
        }
        
        Ok(output_table)
    }

    /// Execute a query with formatted EXPLAIN output only (no performance analysis)
    pub async fn execute_explain_query_formatted(
        &mut self,
        query: &str,
    ) -> std::result::Result<Vec<Vec<String>>, Box<dyn StdError>> {
        debug_log!("[execute_explain_query_formatted] Executing formatted EXPLAIN query");
        
        // Try using the new database abstraction layer first
        if let Some(ref database_client) = self.database_client {
            debug_log!("[execute_explain_query_formatted] Using database abstraction layer for formatted EXPLAIN");
            
            // First get the raw JSON for copying, then get formatted output for display
            match database_client.get_connection_info().database_type {
                crate::database::DatabaseType::PostgreSQL | crate::database::DatabaseType::MySQL => {
                    match database_client.explain_query_raw(query).await {
                        Ok(raw_results) => {
                            debug_log!("[execute_explain_query_formatted] Got raw results for JSON storage");
                            // Store the JSON plan from the raw results
                            if raw_results.len() > 1 && !raw_results[1].is_empty() {
                                self.last_json_plan = Some(raw_results[1][0].clone());
                                debug_log!("[execute_explain_query_formatted] Stored JSON plan ({} characters)", raw_results[1][0].len());
                            }
                        }
                        Err(e) => {
                            debug_log!("[execute_explain_query_formatted] Failed to get raw JSON: {}", e);
                        }
                    }
                }
                crate::database::DatabaseType::SQLite => {
                    // SQLite doesn't support JSON explain plans for \ecopy
                }
            }
            
            // Now get the formatted analysis for display
            match database_client.explain_query(query).await {
                Ok(results) => {
                    debug_log!("[execute_explain_query_formatted] Database abstraction layer returned {} rows", results.len());
                    return Ok(results);
                },
                Err(e) => {
                    debug_log!("[execute_explain_query_formatted] Database abstraction layer failed: {}", e);
                    return Err(Box::new(e));
                }
            }
        }

        // Legacy PostgreSQL implementation fallback
        debug_log!("[execute_explain_query_formatted] Using legacy PostgreSQL implementation");
        let results = self.execute_explain_query(query).await?;
        
        // For legacy PostgreSQL, also extract and store the JSON plan
        if results.len() > 1 && !results[1].is_empty() {
            self.last_json_plan = Some(results[1][0].clone());
        }
        
        Ok(results)
    }

    /// Test network connectivity to a host:port combination with timeout
    pub async fn test_network_connectivity(host: &str, port: u16, timeout_secs: u64) -> std::result::Result<(), Box<dyn StdError>> {
        debug_log!("[Database::test_network_connectivity] Testing connection to {}:{}", host, port);
        
        // Test DNS resolution first
        match tokio::net::lookup_host(format!("{host}:{port}")).await {
            Ok(mut addresses) => {
                if addresses.next().is_none() {
                    return Err(format!("DNS resolution failed: no addresses found for {host}").into());
                }
                debug_log!("[Database::test_network_connectivity] DNS resolution successful for {}", host);
            }
            Err(e) => {
                return Err(format!("DNS resolution failed for {host}: {e}").into());
            }
        }
        
        // Test TCP connectivity with timeout
        let timeout = std::time::Duration::from_secs(timeout_secs);
        match tokio::time::timeout(timeout, tokio::net::TcpStream::connect(format!("{host}:{port}"))).await {
            Ok(Ok(_)) => {
                debug_log!("[Database::test_network_connectivity] TCP connection successful to {}:{}", host, port);
                Ok(())
            }
            Ok(Err(e)) => {
                Err(format!("TCP connection failed to {host}:{port}: {e}").into())
            }
            Err(_) => {
                Err(format!("Connection timeout to {host}:{port} after {timeout_secs} seconds").into())
            }
        }
    }

    /// Validate database connection and provide detailed error information
    pub async fn validate_connection(&self) -> std::result::Result<(), Box<dyn StdError>> {
        debug_log!("[Database::validate_connection] Validating database connection");
        
        // Use the new database abstraction layer if available
        if let Some(ref database_client) = self.database_client {
            debug_log!("[Database::validate_connection] Using database abstraction layer");
            let connection_info = database_client.get_connection_info();
            
            match connection_info.database_type {
                crate::database::DatabaseType::SQLite => {
                    // For SQLite, check if file exists and is readable
                    if let Some(ref file_path) = connection_info.file_path {
                        if file_path == ":memory:" {
                            debug_log!("[Database::validate_connection] SQLite in-memory database");
                            return Ok(()); // In-memory databases are always valid once created
                        }
                        
                        if !std::path::Path::new(file_path).exists() {
                            return Err(format!(
                                "SQLite database file does not exist: {file_path}\n\
                                Please check:\n\
                                ‚Ä¢ File path is correct\n\
                                ‚Ä¢ File exists and is accessible\n\
                                ‚Ä¢ You have read permissions"
                            ).into());
                        }
                    }
                }
                crate::database::DatabaseType::PostgreSQL | crate::database::DatabaseType::MySQL => {
                    // For networked databases, test connectivity
                    let host = connection_info.host.as_deref().unwrap_or("localhost");
                    let port = connection_info.port.unwrap_or({
                        match connection_info.database_type {
                            crate::database::DatabaseType::PostgreSQL => 5432,
                            crate::database::DatabaseType::MySQL => 3306,
                            _ => 5432,
                        }
                    });
                    
                    // Test DNS resolution first
                    match tokio::net::lookup_host(format!("{host}:{port}")).await {
                        Ok(mut addresses) => {
                            if addresses.next().is_none() {
                                return Err(format!(
                                    "DNS resolution failed for host: {host}\n\
                                    Please check:\n\
                                    ‚Ä¢ Host name is correct\n\
                                    ‚Ä¢ DNS server is reachable\n\
                                    ‚Ä¢ Network connectivity"
                                ).into());
                            }
                        }
                        Err(e) => {
                            return Err(format!(
                                "DNS resolution failed for {host}:{port}: {e}\n\
                                Please check:\n\
                                ‚Ä¢ Host name '{host}' is correct\n\
                                ‚Ä¢ DNS server is reachable\n\
                                ‚Ä¢ Network connectivity\n\
                                ‚Ä¢ No typos in hostname"
                            ).into());
                        }
                    }
                    
                    // Test TCP connectivity
                    let timeout = std::time::Duration::from_secs(10);
                    match tokio::time::timeout(timeout, tokio::net::TcpStream::connect(format!("{host}:{port}"))).await {
                        Ok(Ok(_)) => {
                            debug_log!("[Database::validate_connection] TCP connection successful to {}:{}", host, port);
                        }
                        Ok(Err(e)) => {
                            return Err(format!(
                                "Cannot connect to {}:{}: {}\n\
                                Please check:\n\
                                ‚Ä¢ Database server is running\n\
                                ‚Ä¢ Port {} is correct for {}\n\
                                ‚Ä¢ Firewall allows connections\n\
                                ‚Ä¢ Host '{}' is reachable",
                                host, port, e, port, connection_info.database_type, host
                            ).into());
                        }
                        Err(_) => {
                            return Err(format!(
                                "Connection timeout to {host}:{port}\n\
                                Please check:\n\
                                ‚Ä¢ Database server is running and responding\n\
                                ‚Ä¢ Network connectivity is stable\n\
                                ‚Ä¢ No firewall blocking connections\n\
                                ‚Ä¢ Host '{host}' is reachable"
                            ).into());
                        }
                    }
                }
            }
            
            // Test database connection with a simple query
            match database_client.execute_query("SELECT 1").await {
                Ok(_) => {
                    debug_log!("[Database::validate_connection] Database query test successful");
                    Ok(())
                }
                Err(e) => {
                    let db_type = &connection_info.database_type;
                    let username = connection_info.username.as_deref().unwrap_or("unknown");
                    let database = connection_info.database.as_deref().unwrap_or("unknown");
                    
                    // Provide database-specific error messages
                    let error_msg = match db_type {
                        crate::database::DatabaseType::PostgreSQL => {
                            format!(
                                "PostgreSQL connection failed: {e}\n\
                                Please check:\n\
                                ‚Ä¢ Username '{username}' exists and has login privileges\n\
                                ‚Ä¢ Password is correct (check .pgpass file)\n\
                                ‚Ä¢ Database '{database}' exists and user has access\n\
                                ‚Ä¢ PostgreSQL server is accepting connections\n\
                                ‚Ä¢ SSL settings if required"
                            )
                        }
                        crate::database::DatabaseType::MySQL => {
                            format!(
                                "MySQL connection failed: {e}\n\
                                Please check:\n\
                                ‚Ä¢ Username '{username}' exists and has login privileges\n\
                                ‚Ä¢ Password is correct (check .my.cnf file)\n\
                                ‚Ä¢ Database '{database}' exists and user has access\n\
                                ‚Ä¢ MySQL server is accepting connections\n\
                                ‚Ä¢ SSL settings if required"
                            )
                        }
                        crate::database::DatabaseType::SQLite => {
                            format!(
                                "SQLite connection failed: {e}\n\
                                Please check:\n\
                                ‚Ä¢ Database file has correct permissions\n\
                                ‚Ä¢ SQLite database is not corrupted\n\
                                ‚Ä¢ Sufficient disk space available"
                            )
                        }
                    };
                    
                    Err(error_msg.into())
                }
            }
        } else {
            // Legacy PostgreSQL validation
            debug_log!("[Database::validate_connection] Using legacy PostgreSQL validation");
            
            if let Some(ref pool) = self.pool {
                match sqlx::query("SELECT 1").fetch_one(pool).await {
                    Ok(_) => {
                        debug_log!("[Database::validate_connection] Legacy PostgreSQL connection valid");
                        Ok(())
                    }
                    Err(e) => {
                        Err(format!(
                            "PostgreSQL connection failed: {}\n\
                            Please check:\n\
                            ‚Ä¢ Username '{}' exists and has login privileges\n\
                            ‚Ä¢ Password is correct\n\
                            ‚Ä¢ Database '{}' exists and user has access\n\
                            ‚Ä¢ PostgreSQL server is running and accepting connections",
                            e, self.user, self.current_dbname
                        ).into())
                    }
                }
            } else {
                Err("Database connection not initialized".into())
            }
        }
    }

    pub async fn get_table_details(
        &mut self,
        table_name: &str,
    ) -> std::result::Result<TableDetails, Box<dyn StdError>> {
        // Use the new database abstraction layer if available
        if let Some(ref database_client) = self.database_client {
            match database_client.get_metadata_provider().get_table_details(table_name, None).await {
                Ok(table_details) => return Ok(table_details),
                Err(e) => {
                    debug_log!("Error using database client for get_table_details: {}", e);
                    // For non-PostgreSQL databases, return the error instead of falling back
                    if database_client.get_connection_info().database_type != crate::database::DatabaseType::PostgreSQL {
                        return Err(Box::new(e));
                    }
                    // Fall through to legacy implementation for PostgreSQL
                }
            }
        }
        
        if self.pool.is_none() {
            // Mock implementation for tests
            let (schema_str, name_str) = if let Some(idx) = table_name.find('.') {
                (&table_name[..idx], &table_name[idx + 1..])
            } else {
                ("public", table_name) // Default to public schema if not specified
            };

            if name_str == "users" && (schema_str == "public" || schema_str == "test_schema") {
                return Ok(TableDetails {
                    name: name_str.to_string(),
                    schema: schema_str.to_string(),
                    full_name: format!("{schema_str}.{name_str}"),
                    columns: vec![
                        ColumnInfo {
                            name: "id".to_string(),
                            data_type: "integer".to_string(),
                            collation: String::new(),
                            nullable: false,
                            default_value: None,
                        },
                        ColumnInfo {
                            name: "name".to_string(),
                            data_type: "text".to_string(),
                            collation: String::new(),
                            nullable: true,
                            default_value: None,
                        },
                        ColumnInfo {
                            name: "email".to_string(),
                            data_type: "text".to_string(),
                            collation: String::new(),
                            nullable: true,
                            default_value: None,
                        },
                    ],
                    indexes: Vec::new(),
                    check_constraints: Vec::new(),
                    foreign_keys: Vec::new(),
                    referenced_by: Vec::new(),
                });
            } else if name_str == "orders"
                && (schema_str == "public" || schema_str == "test_schema")
            {
                return Ok(TableDetails {
                    name: name_str.to_string(),
                    schema: schema_str.to_string(),
                    full_name: format!("{name_str}.{schema_str}"),
                    columns: vec![
                        ColumnInfo {
                            name: "order_id".to_string(),
                            data_type: "integer".to_string(),
                            collation: String::new(),
                            nullable: false,
                            default_value: None,
                        },
                        ColumnInfo {
                            name: "item_name".to_string(),
                            data_type: "text".to_string(),
                            collation: String::new(),
                            nullable: true,
                            default_value: None,
                        },
                    ],
                    indexes: Vec::new(),
                    check_constraints: Vec::new(),
                    foreign_keys: Vec::new(),
                    referenced_by: Vec::new(),
                });
            }
            return Err(Box::from(format!(
                "Mock table details not found for {table_name}"
            )));
        }

        // Non-mock path (real database interaction)
        let pool_ref = self.pool.as_ref().ok_or_else(|| {
            Box::<dyn StdError>::from("Database pool not initialized for get_table_details")
        })?;

        let (schema, name) = if let Some(idx) = table_name.find('.') {
            (
                table_name[..idx].to_string(),
                table_name[idx + 1..].to_string(),
            )
        } else {
            ("public".to_string(), table_name.to_string())
        };

        // Fetch columns
        let columns_query = r#"
            SELECT
                a.attname AS column_name,
                pg_catalog.format_type(a.atttypid, a.atttypmod) AS data_type,
                coll.collname AS collation_name,
                a.attnotnull AS is_not_nullable,
                pg_get_expr(def.adbin, def.adrelid) AS default_value
            FROM
                pg_catalog.pg_attribute a
            JOIN
                pg_catalog.pg_class c ON a.attrelid = c.oid
            JOIN
                pg_catalog.pg_namespace n ON c.relnamespace = n.oid
            LEFT JOIN
                pg_catalog.pg_collation coll ON coll.oid = a.attcollation
            LEFT JOIN
                pg_catalog.pg_attrdef def ON adrelid = c.oid AND adnum = a.attnum
            WHERE
                n.nspname = $1 AND c.relname = $2 AND a.attnum > 0 AND NOT a.attisdropped
            ORDER BY
                a.attnum;
        "#;
        let columns_rows = sqlx::query(columns_query)
            .bind(&schema) // Bind schema first
            .bind(&name) // Then name
            .fetch_all(pool_ref)
            .await?;

        let mut column_details = Vec::new();
        for row in columns_rows {
            column_details.push(ColumnInfo {
                name: row.try_get("column_name")?,
                data_type: row.try_get("data_type")?,
                collation: row
                    .try_get("collation_name")
                    .unwrap_or_else(|_: sqlx::Error| String::new()),
                nullable: !row.try_get::<bool, _>("is_not_nullable")?,
                default_value: row.try_get("default_value").ok(),
            });
        }

        // Fetch indexes
        let indexes_query = r#"
            SELECT
                i.relname AS index_name,
                am.amname AS index_type,
                idx.indisprimary AS is_primary,
                idx.indisunique AS is_unique,
                pg_get_indexdef(idx.indexrelid) AS index_definition,
                pg_get_constraintdef(con.oid) AS constraint_definition,
                pg_get_expr(idx.indpred, idx.indrelid, true) as predicate
            FROM
                pg_catalog.pg_index idx
            JOIN
                pg_catalog.pg_class i ON i.oid = idx.indexrelid
            JOIN
                pg_catalog.pg_class t ON t.oid = idx.indrelid
            JOIN
                pg_catalog.pg_namespace n ON t.relnamespace = n.oid
            LEFT JOIN
                pg_catalog.pg_am am ON am.oid = i.relam
            LEFT JOIN
                pg_catalog.pg_constraint con ON con.conindid = idx.indexrelid AND con.contype IN ('p', 'u')
            WHERE
                n.nspname = $1 AND t.relname = $2
            ORDER BY
                i.relname;
        "#;
        let index_rows = sqlx::query(indexes_query)
            .bind(&schema) // Bind schema first
            .bind(&name) // Then name
            .fetch_all(pool_ref)
            .await?;

        let mut index_details_vec = Vec::new();
        for row in index_rows {
            index_details_vec.push(IndexInfo {
                name: row.try_get("index_name")?,
                index_type: row.try_get("index_type")?,
                is_primary: row.try_get("is_primary")?,
                is_unique: row.try_get("is_unique")?,
                predicate: row.try_get("predicate").ok(),
                definition: row.try_get("index_definition")?,
                constraint_def: row.try_get("constraint_definition").ok(),
            });
        }

        // Deduplicate indexes by name, prefer primary/unique if names clash (though unlikely for well-defined DBs)
        let mut unique_indexes = HashMap::new();
        for index_info in index_details_vec {
            unique_indexes
                .entry(index_info.name.clone())
                .and_modify(|e: &mut IndexInfo| {
                    // If current is not primary/unique but new one is, replace
                    if (!e.is_primary && !e.is_unique)
                        && (index_info.is_primary || index_info.is_unique)
                    {
                        *e = index_info.clone(); // Clone here if index_info is used later
                    }
                })
                .or_insert(index_info); // index_info is consumed here if not cloned in and_modify
        }
        let final_index_details: Vec<IndexInfo> = unique_indexes.into_values().collect();

        // Fetch check constraints
        let ccs_query = r#"
            SELECT
                con.conname AS constraint_name,
                pg_get_constraintdef(con.oid) AS definition
            FROM
                pg_catalog.pg_constraint con
            JOIN
                pg_catalog.pg_class c ON con.conrelid = c.oid
            JOIN
                pg_catalog.pg_namespace n ON c.relnamespace = n.oid
            WHERE
                n.nspname = $1 AND c.relname = $2 AND con.contype = 'c'
            ORDER BY
                con.conname;
        "#;
        let ccs_rows = sqlx::query(ccs_query)
            .bind(&schema) // Bind schema first
            .bind(&name) // Then name
            .fetch_all(pool_ref)
            .await?;

        let mut cc_details = Vec::new();
        for row in ccs_rows {
            cc_details.push(CheckConstraintInfo {
                name: row.try_get("constraint_name")?,
                definition: row.try_get("definition")?,
            });
        }

        // Fetch foreign key constraints
        let fks_query = r#"
            SELECT
                con.conname AS constraint_name,
                pg_get_constraintdef(con.oid) AS definition
            FROM
                pg_catalog.pg_constraint con
            JOIN
                pg_catalog.pg_class c ON con.conrelid = c.oid /*This should be conrelid for FKs on this table*/
            JOIN
                pg_catalog.pg_namespace n ON c.relnamespace = n.oid
            WHERE
                n.nspname = $1 AND c.relname = $2 AND con.contype = 'f'
            ORDER BY
                con.conname;
        "#;
        let fks_rows = sqlx::query(fks_query)
            .bind(&schema) // Bind schema first
            .bind(&name) // Then name
            .fetch_all(pool_ref)
            .await?;

        let mut fk_details = Vec::new();
        for row in fks_rows {
            // Was 'fk_row', but 'row' is consistent
            fk_details.push(ForeignKeyInfo {
                name: row.try_get("constraint_name")?,
                definition: row.try_get("definition")?,
            });
        }

        // Fetch tables that reference this table
        let refs_query = r#"
            SELECT
                n2.nspname AS referencing_schema_name,
                c2.relname AS referencing_table_name,
                con.conname AS constraint_name,
                pg_get_constraintdef(con.oid) AS definition
            FROM
                pg_catalog.pg_constraint con
            JOIN
                pg_catalog.pg_class c1 ON con.confrelid = c1.oid /* Foreign key references c1 */
            JOIN
                pg_catalog.pg_namespace n1 ON c1.relnamespace = n1.oid
            JOIN
                pg_catalog.pg_class c2 ON con.conrelid = c2.oid /* Foreign key is on c2 */
            JOIN
                pg_catalog.pg_namespace n2 ON c2.relnamespace = n2.oid
            WHERE
                n1.nspname = $1 AND c1.relname = $2 AND con.contype = 'f'
            ORDER BY
                n2.nspname, c2.relname;
        "#;
        let refs_rows = sqlx::query(refs_query)
            .bind(&schema) // Bind schema first
            .bind(&name) // Then name
            .fetch_all(pool_ref)
            .await?;

        let mut ref_details = Vec::new();
        for row in refs_rows {
            // Was 'ref_item_row', but 'row' is consistent
            ref_details.push(ReferencedByInfo {
                schema: row.try_get("referencing_schema_name")?,
                table: row.try_get("referencing_table_name")?,
                constraint_name: row.try_get("constraint_name")?,
                definition: row.try_get("definition")?,
            });
        }

        Ok(TableDetails {
            name: name.clone(),                        // Clone name for the struct field
            schema: schema.clone(),                    // Clone schema for the struct field
            full_name: format!("{name}.{schema}"), // Use original name and schema for format!
            columns: column_details,
            indexes: final_index_details,
            check_constraints: cc_details,
            foreign_keys: fk_details,
            referenced_by: ref_details,
        })
    }

    async fn execute_explain_query(
        &mut self,
        query: &str,
    ) -> std::result::Result<Vec<Vec<String>>, Box<dyn StdError>> {
        debug_log!("[execute_explain_query] Executing EXPLAIN query");
        
        // Try using the new database abstraction layer first
        if let Some(ref database_client) = self.database_client {
            debug_log!("[execute_explain_query] Using database abstraction layer for EXPLAIN");
            
            // First get the raw JSON for copying, then get formatted output for display
            match database_client.get_connection_info().database_type {
                crate::database::DatabaseType::PostgreSQL | crate::database::DatabaseType::MySQL => {
                    match database_client.explain_query_raw(query).await {
                        Ok(raw_results) => {
                            debug_log!("[execute_explain_query] Got raw results for JSON storage");
                            // Store the JSON plan from the raw results
                            if raw_results.len() > 1 && !raw_results[1].is_empty() {
                                self.last_json_plan = Some(raw_results[1][0].clone());
                                debug_log!("[execute_explain_query] Stored JSON plan ({} characters)", raw_results[1][0].len());
                            }
                        }
                        Err(e) => {
                            debug_log!("[execute_explain_query] Failed to get raw JSON: {}", e);
                        }
                    }   
                }
                crate::database::DatabaseType::SQLite => {
                    // SQLite doesn't support JSON explain plans for \ecopy
                }
            }
            
            // Now get the formatted analysis for display
            match database_client.explain_query(query).await {
                Ok(results) => {
                    debug_log!("[execute_explain_query] Database abstraction layer returned {} rows", results.len());
                    return Ok(results);
                },
                Err(e) => {
                    debug_log!("[execute_explain_query] Database abstraction layer failed: {}", e);
                    // For non-PostgreSQL databases, return the error instead of falling back
                    if database_client.get_connection_info().database_type != crate::database::DatabaseType::PostgreSQL {
                        return Err(Box::new(e));
                    }
                    // Fall through to legacy PostgreSQL implementation
                }
            }
        }

        // Legacy PostgreSQL implementation
        debug_log!("[execute_explain_query] Using legacy PostgreSQL implementation");
        
        if self.pool.is_none() {
            // Mock EXPLAIN output
            return Ok(vec![
                vec!["QUERY PLAN".to_string()],
                vec!["Mocked Explain Output".to_string()],
                vec![" -> Seq Scan on mock_table (cost=0.00..1.00 rows=1 width=1)".to_string()],
            ]);
        }
        let pool_ref = self.pool.as_ref().ok_or_else(|| {
            Box::<dyn StdError>::from("Database pool not initialized for execute_explain_query")
        })?;

        // EXPLAIN (FORMAT JSON) returns a JSON array, usually with one element which is an object.
        // Each object is a plan tree.
        let explain_query = format!("EXPLAIN (FORMAT JSON) {query}");
        let explain_results: Vec<JsonValue> = sqlx::query_scalar(&explain_query)
            .fetch_all(pool_ref)
            .await?;

        if explain_results.is_empty() {
            return Ok(vec![
                vec!["QUERY PLAN".to_string()],
                vec!["(No plan returned)".to_string()],
            ]);
        }

        // We'll format each plan tree. Often there's just one.
        let mut output_table = vec![vec!["QUERY PLAN".to_string()]]; // Header
        for (i, plan_json) in explain_results.iter().enumerate() {
            if explain_results.len() > 1 {
                output_table.push(vec![format!("--- Plan {} ---", i + 1)]);
            }
            match self.format_explain_plan(plan_json).await {
                Ok(plan_text) => {
                    for line in plan_text.lines() {
                        output_table.push(vec![line.to_string()]);
                    }
                }
                Err(e) => {
                    output_table.push(vec![format!("Error formatting plan: {}", e)]);
                }
            }
        }
        
        // Store the JSON plan for copying (first plan if multiple)
        if !explain_results.is_empty() {
            self.last_json_plan = Some(explain_results[0].to_string());
        }
        
        Ok(output_table)
    }

    async fn format_explain_plan(
        &self,
        plan_data: &JsonValue,
    ) -> std::result::Result<String, Box<dyn StdError>> {
        if let JsonValue::Array(plans) = plan_data {
            if let Some(plan) = plans.first() {
                if let Some(_plan_obj) = plan.as_object() {
                    let mut output = String::new();

                    // Use PerformanceAnalyzer for consistent rich formatting across all connection types
                    let performance_metrics = crate::performance_analyzer::PerformanceAnalyzer::analyze_postgresql_plan(plan_data);
                    let performance_summary = crate::performance_analyzer::PerformanceAnalyzer::format_metrics_with_colors(&performance_metrics);
                    
                    for line in performance_summary {
                        output.push_str(&line);
                        output.push('\n');
                    }
                    
                    output.push('\n');
                    output.push_str("üí° Use \\ecopy to copy the raw JSON plan to clipboard\n");

                    return Ok(output);
                }
            }
        }

        Err("Failed to parse explain plan".into())
    }

    pub fn new_for_test() -> Self {
        let config = crate::config::Config::load();
        Self {
            database_client: None, // No database client in test mode
            connection_info_override: None,
            pool: None,
            host: "localhost_test".to_string(),
            port: 54321,
            user: "testuser_mock".to_string(),
            password: Some("testpassword_mock".to_string()),
            current_dbname: "testdb_mock".to_string(),
            expanded_display: false,
            default_limit: 100,
            autocomplete_enabled: config.autocomplete_enabled,
            explain_mode: false,
            column_select_mode: false,
            banner_enabled: config.show_banner,
            column_selection_threshold: config.column_selection_threshold,
            column_views: HashMap::new(),
            last_view_key: None,
            ssh_tunnel: Arc::new(Mutex::new(SSHTunnel::new())),
            original_host: "localhost_test".to_string(),
            original_port: 54321,
            last_json_plan: None,
            // shared_runtime: None,
        }
    }

    pub async fn list_database_names(
        &mut self,
    ) -> std::result::Result<Vec<String>, Box<dyn StdError>> {
        if self.pool.is_none() {
            // Mock implementation for tests
            return Ok(vec!["main_db".to_string(), "test_db".to_string()]);
        }
        let pool = self.pool.as_ref().ok_or("Database pool not initialized")?;
        let rows = sqlx::query("SELECT datname FROM pg_database WHERE datistemplate = false;")
            .fetch_all(pool)
            .await?;
        let mut names = Vec::new();
        for row in rows {
            names.push(row.try_get(0)?);
        }
        Ok(names)
    }

    pub async fn get_tables_and_views(
        &mut self,
        schema_filter: Option<&str>,
    ) -> std::result::Result<Vec<String>, Box<dyn StdError>> {
        let start_time = std::time::Instant::now();
        debug_log!(
            "[get_tables_and_views] Starting query for schema_filter: {:?}",
            schema_filter
        );

        // Use the new database abstraction layer if available
        if let Some(ref database_client) = self.database_client {
            debug_log!("[get_tables_and_views] Using new database abstraction layer");
            match database_client.get_metadata_provider().get_tables(schema_filter).await {
                Ok(tables) => {
                    let duration = start_time.elapsed();
                    debug_log!(
                        "[get_tables_and_views] Database abstraction layer returned {} tables in {:?}",
                        tables.len(),
                        duration
                    );
                    return Ok(tables);
                }
                Err(e) => {
                    debug_log!("Error using database client for get_tables_and_views: {}", e);
                    // For non-PostgreSQL databases, return the error instead of falling back
                    if database_client.get_connection_info().database_type != crate::database::DatabaseType::PostgreSQL {
                        return Err(Box::new(e));
                    }
                    // Fall through to legacy implementation for PostgreSQL
                }
            }
        }

        if self.pool.is_none() {
            // Mock implementation for tests
            debug_log!("[get_tables_and_views] Using mock implementation (no pool)");
            let mock_result = if let Some(sf) = schema_filter {
                if sf == "custom_schema" {
                    vec!["custom_table1".to_string()]
                } else if sf == "public" {
                    vec!["users".to_string(), "orders".to_string()]
                } else {
                    Vec::new() // Empty if schema doesn't match known mock schemas
                }
            } else {
                vec![
                    "users".to_string(),
                    "orders".to_string(),
                    "custom_table1".to_string(),
                ]
            };
            let duration = start_time.elapsed();
            debug_log!(
                "[get_tables_and_views] Mock returned {} tables in {:?}",
                mock_result.len(),
                duration
            );
            return Ok(mock_result);
        }

        let build_query_start = std::time::Instant::now();
        let pool = self.pool.as_ref().ok_or("Database pool not initialized")?;

        // Use optimized pg_catalog queries instead of information_schema views
        let query = if let Some(schema) = schema_filter {
            debug_log!(
                "[get_tables_and_views] Using schema-specific pg_catalog query for '{}'",
                schema
            );
            sqlx::query(
                r#"
                SELECT c.relname as table_name
                FROM pg_class c
                INNER JOIN pg_namespace n ON c.relnamespace = n.oid
                WHERE c.relkind IN ('r', 'v', 'm', 'f', 'p')  -- tables, views, materialized views, foreign tables, partitioned tables
                  AND n.nspname = $1
                ORDER BY c.relname
                "#,
            ).bind(schema)
        } else {
            debug_log!("[get_tables_and_views] Using full pg_catalog query");
            sqlx::query(
                r#"
                SELECT c.relname as table_name
                FROM pg_class c
                INNER JOIN pg_namespace n ON c.relnamespace = n.oid
                WHERE c.relkind IN ('r', 'v', 'm', 'f', 'p')  -- tables, views, materialized views, foreign tables, partitioned tables
                  AND n.nspname NOT LIKE 'pg_%'
                  AND n.nspname NOT IN ('information_schema', 'pg_toast')
                ORDER BY n.nspname, c.relname
                "#,
            )
        };

        debug_log!(
            "[get_tables_and_views] Query built in {:?}",
            build_query_start.elapsed()
        );

        let fetch_start = std::time::Instant::now();
        debug_log!("[get_tables_and_views] Starting fetch from database");
        let rows = query.fetch_all(pool).await?;

        debug_log!(
            "[get_tables_and_views] Fetch completed in {:?}, got {} rows",
            fetch_start.elapsed(),
            rows.len()
        );

        let mut names = Vec::new();
        for row in rows {
            names.push(row.try_get(0)?);
        }

        let duration = start_time.elapsed();
        debug_log!(
            "[get_tables_and_views] Successfully returned {} tables in {:?}",
            names.len(),
            duration
        );
        Ok(names)
    }

    pub async fn get_schemas(&mut self) -> std::result::Result<Vec<String>, Box<dyn StdError>> {
        let start_time = std::time::Instant::now();
        debug_log!("[get_schemas] Starting query");

        // Use the new database abstraction layer if available
        if let Some(ref database_client) = self.database_client {
            debug_log!("[get_schemas] Using new database abstraction layer");
            match database_client.get_metadata_provider().get_schemas().await {
                Ok(schemas) => {
                    let duration = start_time.elapsed();
                    debug_log!(
                        "[get_schemas] Database abstraction layer returned {} schemas in {:?}",
                        schemas.len(),
                        duration
                    );
                    return Ok(schemas);
                }
                Err(e) => {
                    debug_log!("Error using database client for get_schemas: {}", e);
                    // For non-PostgreSQL databases, return the error instead of falling back
                    if database_client.get_connection_info().database_type != crate::database::DatabaseType::PostgreSQL {
                        return Err(Box::new(e));
                    }
                    // Fall through to legacy implementation for PostgreSQL
                }
            }
        }

        if self.pool.is_none() {
            // Mock implementation for tests
            debug_log!("[get_schemas] Using mock implementation (no pool)");
            let mock_result = vec!["public".to_string(), "custom_schema".to_string()];
            let duration = start_time.elapsed();
            debug_log!(
                "[get_schemas] Mock returned {} schemas in {:?}",
                mock_result.len(),
                duration
            );
            return Ok(mock_result);
        }

        let pool = self.pool.as_ref().ok_or("Database pool not initialized")?;

        let fetch_start = std::time::Instant::now();
        debug_log!("[get_schemas] Starting fetch from database");
        let rows = sqlx::query(
            r#"
            SELECT nspname FROM pg_namespace
            WHERE nspname NOT LIKE 'pg_%' AND nspname <> 'information_schema'
            ORDER BY nspname;
        "#,
        )
        .fetch_all(pool)
        .await?;
        debug_log!(
            "[get_schemas] Fetch completed in {:?}, got {} rows",
            fetch_start.elapsed(),
            rows.len()
        );

        let mut names = Vec::new();
        for row in rows {
            names.push(row.try_get(0)?);
        }

        let duration = start_time.elapsed();
        debug_log!(
            "[get_schemas] Successfully returned {} schemas in {:?}",
            names.len(),
            duration
        );
        Ok(names)
    }

    pub async fn get_functions(
        &mut self,
        schema_filter: Option<&str>,
    ) -> std::result::Result<Vec<String>, Box<dyn StdError>> {
        if self.pool.is_none() {
            // Mock implementation for tests
            if let Some(sf) = schema_filter {
                if sf == "public" {
                    return Ok(vec!["func1_public".to_string()]);
                } else {
                    return Ok(Vec::new());
                }
            }
            return Ok(vec![
                "func1_public".to_string(),
                "func2_any_schema".to_string(),
            ]);
        }
        let pool = self.pool.as_ref().ok_or("Database pool not initialized")?;
        let mut query_builder = sqlx::QueryBuilder::new(
            r#"
            SELECT proname
            FROM pg_proc p
            JOIN pg_namespace n ON p.pronamespace = n.oid
            WHERE p.prokind = 'f' -- Only functions, not procedures or aggregates"#,
        );

        if let Some(schema) = schema_filter {
            query_builder.push(" AND n.nspname = $1");
            query_builder.push(" ORDER BY proname;");
            query_builder.push_bind(schema);
        } else {
            query_builder
                .push(" AND n.nspname NOT LIKE 'pg_%' AND n.nspname <> 'information_schema'");
            query_builder.push(" ORDER BY proname;");
        }

        let query = query_builder.build();
        let rows = query.fetch_all(pool).await?; // Corrected: use query directly

        let mut names = Vec::new();
        for row in rows {
            names.push(row.try_get(0)?);
        }
        Ok(names)
    }

    pub async fn get_columns_for_table(
        &mut self,
        table_name: &str,
        schema: Option<&str>,
    ) -> std::result::Result<Vec<String>, Box<dyn StdError>> {
        let start_time = std::time::Instant::now();
        debug_log!(
            "[get_columns_for_table] Starting query for table: '{}', schema: {:?}",
            table_name,
            schema
        );

        // Use the new database abstraction layer if available
        if let Some(ref database_client) = self.database_client {
            debug_log!("[get_columns_for_table] Using new database abstraction layer");
            match database_client.get_metadata_provider().get_columns(table_name, schema).await {
                Ok(columns) => {
                    let duration = start_time.elapsed();
                    debug_log!(
                        "[get_columns_for_table] Database abstraction layer returned {} columns in {:?}",
                        columns.len(),
                        duration
                    );
                    return Ok(columns);
                }
                Err(e) => {
                    debug_log!("Error using database client for get_columns_for_table: {}", e);
                    // For non-PostgreSQL databases, return the error instead of falling back
                    if database_client.get_connection_info().database_type != crate::database::DatabaseType::PostgreSQL {
                        return Err(Box::new(e));
                    }
                    // Fall through to legacy implementation for PostgreSQL
                }
            }
        }

        if self.pool.is_none() {
            // Mock implementation for tests
            debug_log!("[get_columns_for_table] Using mock implementation (no pool)");
            let schema_str = schema.unwrap_or("public");
            let mock_result = if table_name == "users" && schema_str == "public" {
                vec![
                    "id".to_string(),
                    "name".to_string(),
                    "email".to_string(),
                    "created_at".to_string(),
                ]
            } else if table_name == "orders"
                && (schema_str == "public" || schema_str == "test_schema")
            {
                vec!["order_id".to_string(), "item_name".to_string()]
            } else {
                Vec::new()
            };
            let duration = start_time.elapsed();
            debug_log!(
                "[get_columns_for_table] Mock returned {} columns in {:?}",
                mock_result.len(),
                duration
            );
            return Ok(mock_result);
        }

        let build_query_start = std::time::Instant::now();
        let pool = self.pool.as_ref().ok_or("Database pool not initialized")?;

        // Default to public schema if none provided
        let schema_name = schema.unwrap_or("public");

        // Use optimized pg_catalog query instead of information_schema view
        let query = r#"
            SELECT a.attname as column_name
            FROM pg_attribute a
            INNER JOIN pg_class c ON a.attrelid = c.oid
            INNER JOIN pg_namespace n ON c.relnamespace = n.oid
            WHERE n.nspname = $1 
              AND c.relname = $2
              AND a.attnum > 0  -- exclude system columns
              AND NOT a.attisdropped  -- exclude dropped columns
            ORDER BY a.attnum;
        "#;
        debug_log!(
            "[get_columns_for_table] Query built in {:?}",
            build_query_start.elapsed()
        );

        // Execute the query
        let fetch_start = std::time::Instant::now();
        debug_log!("[get_columns_for_table] Starting fetch from database");
        let rows = sqlx::query(query)
            .bind(schema_name)
            .bind(table_name)
            .fetch_all(pool)
            .await?;
        debug_log!(
            "[get_columns_for_table] Fetch completed in {:?}, got {} rows",
            fetch_start.elapsed(),
            rows.len()
        );

        // Extract column names from the result
        let mut column_names = Vec::new();
        for row in rows {
            column_names.push(row.try_get(0)?);
        }

        let duration = start_time.elapsed();
        debug_log!(
            "[get_columns_for_table] Successfully returned {} columns in {:?}",
            column_names.len(),
            duration
        );
        Ok(column_names)
    }

    pub fn is_column_select_mode(&self) -> bool {
        self.column_select_mode
    }

    pub fn toggle_column_select_mode(&mut self) -> bool {
        self.column_select_mode = !self.column_select_mode;
        self.column_select_mode
    }

    pub fn is_banner_enabled(&self) -> bool {
        self.banner_enabled
    }

    pub fn toggle_banner_enabled(&mut self) -> bool {
        self.banner_enabled = !self.banner_enabled;
        self.banner_enabled
    }

    pub fn save_column_view(&mut self, view_name: &str, columns: Vec<String>) {
        self.column_views.insert(view_name.to_string(), columns);
        self.last_view_key = Some(view_name.to_string());
    }

    pub fn get_column_view(&self, view_name: &str) -> Option<&Vec<String>> {
        self.column_views.get(view_name)
    }

    // Generates a key for the column set based on header names
    pub fn generate_column_view_key(&self, headers: &[String]) -> String {
        headers.join(":")
    }
    pub fn interactive_column_selection(
        &mut self,
        data: &[Vec<String>],
        interrupt_flag: &Arc<AtomicBool>,
    ) -> Result<Vec<Vec<String>>, Box<dyn StdError>> {
        // Use the new method that returns metadata and extract just the data
        match self.interactive_column_selection_with_info(data, interrupt_flag) {
            Ok(results_with_info) => Ok(results_with_info.data),
            Err(e) => Err(e),
        }
    }

    pub fn interactive_column_selection_with_info(
        &mut self,
        data: &[Vec<String>],
        _interrupt_flag: &Arc<AtomicBool>,
    ) -> Result<QueryResultsWithInfo, Box<dyn StdError>> {
        // For testing purposes, we'll add a special case that provides a mocked input
        // This is only used in tests and won't affect normal operation
        #[cfg(test)]
        if !data.is_empty() && !data[0].is_empty() && data[0][0] == "test_mock_input" {
            // In test mode, return a pre-filtered set based on the test case
            return Ok(QueryResultsWithInfo {
                data: data.to_vec(),
                column_info: None,
            });
        }

        if data.is_empty() {
            return Ok(QueryResultsWithInfo {
                data: Vec::new(),
                column_info: None,
            });
        }

        // Get the header row
        let header = &data[0];

        // Generate a key for this column set
        let view_key = self.generate_column_view_key(header);

        // Check if we already have a saved view for this column set
        if let Some(selected_columns) = self.get_column_view(&view_key) {
            // Create a new filtered dataset
            let mut filtered_data = Vec::new();
            let mut index_map = Vec::new();

            // First find which columns we need to include (by index)
            for (idx, col_name) in header.iter().enumerate() {
                if selected_columns.contains(col_name) {
                    index_map.push(idx);
                }
            }

            // Create a new header with only the selected columns
            let filtered_header: Vec<String> =
                index_map.iter().map(|&idx| header[idx].clone()).collect();

            filtered_data.push(filtered_header.clone());

            // Now add each data row with only the selected columns
            for row in data.iter().skip(1) {
                let filtered_row: Vec<String> =
                    index_map.iter().map(|&idx| row[idx].clone()).collect();
                filtered_data.push(filtered_row);
            }

            // Create column filtering info for saved view
            let column_info = if selected_columns.len() < header.len() {
                Some(ColumnFilteringInfo::new(
                    header.len(),
                    selected_columns.len(),
                    filtered_header,
                ))
            } else {
                None
            };

            return Ok(QueryResultsWithInfo {
                data: filtered_data,
                column_info,
            });
        }

        // Use inquire for interactive column selection
        use inquire::MultiSelect;
        
        let column_options: Vec<&String> = header.iter().collect();
        
        match MultiSelect::new("Select columns to display:", column_options)
            .with_help_message("Use Space to select/deselect, Enter to confirm, Ctrl-C to abort")
            .prompt()
        {
            Ok(selected_columns) => {
                if selected_columns.is_empty() {
                    // If nothing selected, show all columns
                    println!("No columns selected, showing all {} columns", header.len());
                    return Ok(QueryResultsWithInfo {
                        data: data.to_vec(),
                        column_info: None,
                    });
                }
                
                // Find indices of selected columns
                let selected_indices: Vec<usize> = selected_columns
                    .iter()
                    .filter_map(|&col| header.iter().position(|h| h == col))
                    .collect();
                    
                println!("Showing {} of {} columns", selected_indices.len(), header.len());
                
                // Create the filtered dataset
                let mut filtered_data = Vec::new();

                // Create a new header with only the selected columns
                let filtered_header: Vec<String> = selected_indices
                    .iter()
                    .map(|&idx| header[idx].clone())
                    .collect();

                // Save for future use with the same set of columns
                self.save_column_view(&view_key, filtered_header.clone());

                filtered_data.push(filtered_header.clone());

                // Add each data row with only the selected columns
                for row in data.iter().skip(1) {
                    let filtered_row: Vec<String> = selected_indices
                        .iter()
                        .map(|&idx| {
                            if idx < row.len() {
                                row[idx].clone()
                            } else {
                                // Handle case where row has fewer columns than expected
                                String::new()
                            }
                        })
                        .collect();
                    filtered_data.push(filtered_row);
                }

                // Create column filtering info for interactive selection
                let column_info = if selected_indices.len() < header.len() {
                    Some(ColumnFilteringInfo::new(
                        header.len(),
                        selected_indices.len(),
                        filtered_header,
                    ))
                } else {
                    None
                };

                return Ok(QueryResultsWithInfo {
                    data: filtered_data,
                    column_info,
                });
            }
            Err(inquire::InquireError::OperationCanceled) => {
                // User pressed Ctrl-C - return the abort error
                println!("Column selection aborted");
                return Err(Box::new(ColumnSelectionAborted));
            }
            Err(e) => {
                // Other errors - show all columns
                eprintln!("Column selection error: {}, showing all columns", e);
                return Ok(QueryResultsWithInfo {
                    data: data.to_vec(),
                    column_info: None,
                });
            }
        }
    }

    pub fn clear_column_views(&mut self) {
        self.column_views.clear();
    }

    pub fn should_auto_enable_column_selection(&self, column_count: usize) -> bool {
        // Auto-enable column selection mode if there are more columns than the threshold
        column_count > self.column_selection_threshold
    }

    pub fn set_column_selection_threshold(&mut self, threshold: usize) {
        self.column_selection_threshold = threshold;
    }

    pub fn get_last_json_plan(&self) -> Option<String> {
        self.last_json_plan.clone()
    }

    // Method to reset the most recent column view
    pub fn reset_column_view(&mut self) {
        // We'll use a quick approach - store the last used view key when saving a view
        if let Some(last_view_key) = &self.last_view_key {
            self.column_views.remove(last_view_key);
        }
    }

    pub fn get_column_selection_threshold(&self) -> usize {
        self.column_selection_threshold
    }

    pub fn get_original_host(&self) -> &str {
        &self.original_host
    }

    pub fn get_original_port(&self) -> u16 {
        self.original_port
    }

    pub async fn close(&mut self) {
        // Close the database pool
        if let Some(p) = self.pool.take() {
            // Take the pool to close it
            p.close().await;
        }

        // Stop the SSH tunnel
        // No need to take the MutexGuard itself, operate on the Option within it.
        let tunnel_guard = self.ssh_tunnel.lock().unwrap();
        if let Some(ref tunnel_instance) = *tunnel_guard {
            // Check if there's Some(SSHTunnel)
            if tunnel_instance.is_active() {
                // Call is_active() on the SSHTunnel instance
                if let Err(e) = tunnel_instance.stop().await {
                    // Call stop() on the SSHTunnel instance
                    eprintln!("Error stopping SSH tunnel: {e}");
                }
            }
        }
        // If you want to clear the tunnel from the Option after stopping:
        // let mut tunnel_guard_to_clear = self.ssh_tunnel.lock().unwrap();
        // *tunnel_guard_to_clear = None;
    }

    /// Loads essential database metadata in parallel to warm up caches efficiently
    pub async fn preload_metadata(&mut self) -> std::result::Result<(), Box<dyn StdError>> {
        // Try using the new database abstraction layer first
        if let Some(ref database_client) = self.database_client {
            debug_log!("[preload_metadata] Using new database abstraction layer for metadata preload");
            let start_time = std::time::Instant::now();
            
            // Preload schemas and tables in parallel
            let metadata_provider = database_client.get_metadata_provider();
            let (schemas_result, tables_result) = tokio::join!(
                metadata_provider.get_schemas(),
                metadata_provider.get_tables(None)
            );
            
            match (schemas_result, tables_result) {
                (Ok(schemas), Ok(tables)) => {
                    debug_log!(
                        "[preload_metadata] Successfully preloaded {} schemas and {} tables in {:?}",
                        schemas.len(),
                        tables.len(),
                        start_time.elapsed()
                    );
                    return Ok(());
                }
                (Err(e), _) | (_, Err(e)) => {
                    debug_log!("Database abstraction layer preload_metadata failed: {}. Falling back to legacy implementation.", e);
                }
            }
        }

        // Fallback to legacy implementation
        debug_log!("[preload_metadata] Using legacy PostgreSQL implementation for metadata preload");
        
        if self.pool.is_none() {
            return Ok(()); // Skip for tests
        }

        let start_time = std::time::Instant::now();
        debug_log!("[preload_metadata] Starting parallel metadata fetch");

        let pool = self.pool.as_ref().ok_or("Database pool not initialized")?;

        // Run both schema and table queries in parallel
        let (schemas_result, tables_result) = tokio::join!(
            // Query to get schemas
            async {
                debug_log!("[preload_metadata] Starting schemas query");
                let schemas_start = std::time::Instant::now();
                let result = sqlx::query(
                    r#"
                    SELECT nspname FROM pg_namespace
                    WHERE nspname NOT LIKE 'pg_%' AND nspname <> 'information_schema'
                    ORDER BY nspname;
                "#,
                )
                .fetch_all(pool)
                .await;
                debug_log!(
                    "[preload_metadata] Schemas query completed in {:?}",
                    schemas_start.elapsed()
                );
                result
            },
            // Query to get tables and views (without schema filtering)
            async {
                debug_log!("[preload_metadata] Starting tables query");
                let tables_start = std::time::Instant::now();
                let result = sqlx::query(
                    r#"
                    SELECT table_name FROM information_schema.tables
                    WHERE (table_type = 'BASE TABLE' OR table_type = 'VIEW')
                    AND table_schema NOT IN ('pg_catalog', 'information_schema')
                    ORDER BY table_schema, table_name
                "#,
                )
                .fetch_all(pool)
                .await;
                debug_log!(
                    "[preload_metadata] Tables query completed in {:?}",
                    tables_start.elapsed()
                );
                result
            }
        );

        // Handle results
        match schemas_result {
            Ok(rows) => {
                let count = rows.len();
                debug_log!("[preload_metadata] Successfully fetched {} schemas", count);
            }
            Err(e) => {
                eprintln!("Error preloading schemas: {e}");
            }
        }

        match tables_result {
            Ok(rows) => {
                let count = rows.len();
                debug_log!("[preload_metadata] Successfully fetched {} tables", count);
            }
            Err(e) => {
                eprintln!("Error preloading tables: {e}");
            }
        }

        let duration = start_time.elapsed();
        debug_log!(
            "[preload_metadata] Completed parallel metadata load in {:?}",
            duration
        );

        Ok(())
    }
    
    /// Get query timeout (hardcoded for now, will be configurable later)
    fn get_query_timeout(&self) -> u64 {
        30 // 30 seconds default query timeout
    }
    
    /// Get metadata timeout (hardcoded for now, will be configurable later)
    fn get_metadata_timeout(&self) -> u64 {
        10 // 10 seconds default metadata timeout
    }
}

#[derive(Debug)]
pub struct TableDetails {
    pub name: String,
    pub schema: String,
    #[allow(dead_code)]
    pub full_name: String,
    pub columns: Vec<ColumnInfo>,
    pub indexes: Vec<IndexInfo>,
    pub check_constraints: Vec<CheckConstraintInfo>,
    pub foreign_keys: Vec<ForeignKeyInfo>,
    pub referenced_by: Vec<ReferencedByInfo>,
}

#[derive(Debug)]
pub struct ColumnInfo {
    pub name: String,
    pub data_type: String,
    pub collation: String,
    pub nullable: bool,
    pub default_value: Option<String>,
}

#[derive(Debug, PartialEq, Eq, Hash, Clone)]
pub struct IndexInfo {
    pub name: String,
    pub index_type: String,
    pub is_primary: bool,
    pub is_unique: bool,
    pub predicate: Option<String>,
    pub definition: String,
    #[allow(dead_code)]
    pub constraint_def: Option<String>,
}

#[derive(Debug)]
pub struct ForeignKeyInfo {
    pub name: String,
    pub definition: String,
}

#[derive(Debug)]
pub struct ReferencedByInfo {
    pub table: String,
    pub schema: String,
    pub constraint_name: String,
    pub definition: String,
}

#[derive(Debug)]
pub struct CheckConstraintInfo {
    pub name: String,
    pub definition: String,
}


// Helper function to determine if a query can be explained
fn is_query_explainable(query: &str) -> bool {
    let query = query.trim().to_lowercase();

    // Only try to EXPLAIN statements that make sense
    // Only SELECT and WITH queries should be explainable
    query.starts_with("select") || query.starts_with("with")
}

// Helper function to format PgInterval
fn format_pg_interval_simple(interval: &PgInterval) -> String {
    format!(
        "months: {}, days: {}, microseconds: {}",
        interval.months, interval.days, interval.microseconds
    )
}

// Helper function to format PgMoney
fn format_pg_money(money: &PgMoney) -> String {
    // PgMoney stores amount in cents (or equivalent smallest unit)
    // We'll format it as a decimal with 2 places.
    // Note: This doesn't handle locales or currency symbols.
    format!("{:.2}", money.0 as f64 / 100.0)
}

/// Logs type-related warnings and errors to a dedicated log file in the config directory
fn log_type_error(message: &str) {
    // Use a thread-safe lazy initialized HashSet to track logged messages
    use std::collections::HashSet;
    use std::sync::Mutex;

    // Use OnceLock to create a thread-safe HashSet that is initialized on first use
    static LOGGED_MESSAGES: OnceLock<Mutex<HashSet<String>>> = OnceLock::new();

    // Check if we've already logged this exact message
    let should_log = {
        let mutex = LOGGED_MESSAGES.get_or_init(|| Mutex::new(HashSet::new()));
        if let Ok(mut set) = mutex.lock() {
            if !set.contains(message) {
                set.insert(message.to_string());
                true
            } else {
                false
            }
        } else {
            // If we can't get the lock, just log it anyway
            true
        }
    };

    // Only log if we haven't seen this message before
    if should_log {
        if let Ok(config_dir) = crate::config::Config::get_config_dir() {
            let log_path = config_dir.join("type_errors.log");
            if let Ok(file) = std::fs::OpenOptions::new()
                .append(true)
                .create(true)
                .open(&log_path)
            {
                let mut file = std::io::BufWriter::new(file);
                // Add timestamp to the log entry
                let now = chrono::Local::now();
                let _ = writeln!(file, "[{}] {}", now.format("%Y-%m-%d %H:%M:%S"), message);
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use rstest::rstest;

    #[rstest]
    fn test_is_query_explainable() {
        // Simple select statement - should be explainable
        assert!(is_query_explainable("SELECT * FROM users"));
        assert!(is_query_explainable("select * from users"));
        assert!(is_query_explainable("WITH t AS (SELECT 1) SELECT * FROM t"));

        // DDL and other commands - should not be explainable
        assert!(!is_query_explainable("CREATE TABLE users (id INT)"));
        assert!(!is_query_explainable("INSERT INTO users VALUES (1)"));
        assert!(!is_query_explainable("UPDATE users SET name='john'"));
        assert!(!is_query_explainable("DELETE FROM users"));
        assert!(!is_query_explainable("DROP TABLE users"));
        assert!(!is_query_explainable("TRUNCATE users"));
        assert!(!is_query_explainable("BEGIN"));
        assert!(!is_query_explainable("COMMIT"));
        assert!(!is_query_explainable("ROLLBACK"));
        assert!(!is_query_explainable("-- comment only"));
    }

    #[rstest]
    #[tokio::test]
    async fn test_toggle_explain_mode() {
        let mut db = Database::new_for_test();

        // Default is false
        assert!(!db.is_explain_mode());

        // First toggle should enable
        assert!(db.toggle_explain_mode());
        assert!(db.is_explain_mode());

        // Second toggle should disable
        assert!(!db.toggle_explain_mode());
        assert!(!db.is_explain_mode());
    }

    #[rstest]
    #[tokio::test]
    async fn test_toggle_banner_enabled() {
        let mut db = Database::new_for_test();

        // Default should be false (based on config.show_banner)
        assert!(!db.is_banner_enabled());

        // First toggle should enable
        assert!(db.toggle_banner_enabled());
        assert!(db.is_banner_enabled());

        // Second toggle should disable
        assert!(!db.toggle_banner_enabled());
        assert!(!db.is_banner_enabled());
    }

    #[rstest]
    #[tokio::test]
    async fn test_column_selection_with_ctrl_c() {
        // Create a minimal test database instance
        let mut db = Database::new_for_test();

        // Create test data with special first column that triggers our mock input path
        let test_data = vec![
            vec![
                "test_mock_input".to_string(),
                "col2".to_string(),
                "col3".to_string(),
            ],
            vec!["val1".to_string(), "val2".to_string(), "val3".to_string()],
            vec!["val4".to_string(), "val5".to_string(), "val6".to_string()],
        ];

        // Pass our test data to the function - it will recognize the special marker and skip user input
        let result = db.interactive_column_selection(&test_data, &Arc::new(AtomicBool::new(false)));

        assert!(result.is_ok(), "Column selection should not fail");

        // Verify we get back our test data without changes
        let filtered_data = result.unwrap();
        assert_eq!(filtered_data, test_data);
    }

    #[test]
    fn test_text_array_handling() {
        // This test verifies that the code correctly handles TEXT[] arrays
        // Since we can't easily test with a real database connection here,
        // we're just confirming that the handler is registered for the TEXT[] type
        // and would be used instead of falling back to the warning case

        // Check that we have explicit handling for TEXT[] (in both formats)

        // Check for underscore prefix format (_TEXT)
        let matched_underscore = match "_TEXT" {
            "_TEXT" => true,
            type_name if type_name.starts_with('_') || type_name.ends_with("[]") => false, // This is the warning case
            _ => false,
        };

        // Check for bracket suffix format (TEXT[])
        let matched_brackets = match "TEXT[]" {
            "TEXT[]" => true,
            type_name if type_name.starts_with('_') || type_name.ends_with("[]") => false, // This is the warning case
            _ => false,
        };

        assert!(
            matched_underscore,
            "TEXT[] (_TEXT) type should be explicitly handled"
        );
        assert!(
            matched_brackets,
            "TEXT[] (with brackets) type should be explicitly handled"
        );
    }

    #[test]
    fn test_apply_column_view() {
        // Create a simplified version of Database just for testing apply_column_view
        let mut column_views = HashMap::new();

        // Sample test data
        let test_data = [vec!["col1".to_string(), "col2".to_string(), "col3".to_string()],
            vec!["val1".to_string(), "val2".to_string(), "val3".to_string()],
            vec!["val4".to_string(), "val5".to_string(), "val6".to_string()]];

        // Save a column view with only the first and third columns
        let view_key = "col1:col2:col3"; // This matches the key generation logic
        let selected_columns = vec!["col1".to_string(), "col3".to_string()];
        column_views.insert(view_key.to_string(), selected_columns);

        // Apply the column view - this is a direct implementation of apply_column_view logic
        // to test independently from the database connection
        let filtered_data = {
            let header = &test_data[0];
            let mut filtered_data = Vec::new();
            let mut filtered_header = Vec::new();
            let mut index_map = Vec::new();

            // Get the selected columns from the view
            let selected_columns = column_views.get(view_key).unwrap();

            // Create filtered header and map of visible column indices
            for (idx, col_name) in header.iter().enumerate() {
                if selected_columns.contains(col_name) {
                    filtered_header.push(col_name.clone());
                    index_map.push(idx);
                }
            }

            // Add filtered header to results
            filtered_data.push(filtered_header);

            // Filter each row to only include selected columns
            for row in test_data.iter().skip(1) {
                let filtered_row: Vec<String> =
                    index_map.iter().map(|&idx| row[idx].clone()).collect();
                filtered_data.push(filtered_row);
            }

            filtered_data
        };

        // Verify filtered data structure
        assert_eq!(filtered_data.len(), test_data.len());
        assert_eq!(filtered_data[0].len(), 2); // Should only have 2 columns
        assert_eq!(filtered_data[0][0], "col1");
        assert_eq!(filtered_data[0][1], "col3");
        assert_eq!(filtered_data[1][0], "val1");
        assert_eq!(filtered_data[1][1], "val3");
        assert_eq!(filtered_data[2][0], "val4");
        assert_eq!(filtered_data[2][1], "val6");
    }
    
    #[tokio::test]
    async fn test_ssh_tunnel_pattern_detection() {
        use crate::config::Config;
        
        // Create a test config with SSH tunnel patterns
        let mut config = Config::default();
        config.ssh_tunnel_patterns.insert(
            "^test\\.internal\\..*\\.com$".to_string(),
            "testuser@jumphost.example.com:2222".to_string(),
        );
        
        // Test that get_ssh_tunnel_for_host correctly identifies matching patterns
        let tunnel_config = config.get_ssh_tunnel_for_host("test.internal.example.com");
        assert!(tunnel_config.is_some());
        
        let tunnel = tunnel_config.unwrap();
        assert_eq!(tunnel.ssh_host, "jumphost.example.com");
        assert_eq!(tunnel.ssh_port, 2222);
        assert_eq!(tunnel.ssh_username, Some("testuser".to_string()));
        assert!(tunnel.enabled);
        
        // Test non-matching pattern
        let no_tunnel = config.get_ssh_tunnel_for_host("regular.example.com");
        assert!(no_tunnel.is_none());
    }
    
    #[tokio::test] 
    async fn test_from_url_applies_ssh_tunnel_config() {
        // Test the logic flow without actually establishing SSH tunnel
        // We'll test that the SSH tunnel configuration is correctly passed through
        
        use crate::config::Config;
        
        // Create a URL that would trigger SSH tunnel
        let test_url = "postgres://user:pass@test.internal.example.com:5432/testdb";
        
        // Manually create and test the flow that from_url should follow
        let connection_info = ConnectionInfo::parse_url(test_url).unwrap();
        assert_eq!(connection_info.host, Some("test.internal.example.com".to_string()));
        
        // Create a test config with SSH tunnel pattern
        let mut config = Config::default();
        config.ssh_tunnel_patterns.insert(
            "^test\\.internal\\..*\\.com$".to_string(),
            "testuser@jumphost.example.com:2222".to_string(),
        );
        
        // Test that the pattern is detected
        let ssh_tunnel_config = if let Some(ref host) = connection_info.host {
            config.get_ssh_tunnel_for_host(host)
        } else {
            None
        };
        
        assert!(ssh_tunnel_config.is_some());
        let tunnel = ssh_tunnel_config.unwrap();
        assert_eq!(tunnel.ssh_host, "jumphost.example.com");
        assert_eq!(tunnel.ssh_port, 2222);
        assert_eq!(tunnel.ssh_username, Some("testuser".to_string()));
    }
    
    #[test]
    fn test_ssh_tunnel_config_parsing() {
        use crate::config::Config;
        
        let config = Config::default();
        
        // Test parsing of SSH tunnel string format with port
        let tunnel_str = "user@host.example.com:2222";
        let tunnel_config = config.parse_ssh_tunnel_string(tunnel_str);
        assert!(tunnel_config.is_some());
        let tunnel_config = tunnel_config.unwrap();
        
        assert_eq!(tunnel_config.ssh_host, "host.example.com");
        assert_eq!(tunnel_config.ssh_port, 2222);
        assert_eq!(tunnel_config.ssh_username, Some("user".to_string()));
        assert!(tunnel_config.enabled);
        
        // Test without port (should default to 22)
        let tunnel_str = "user@host.example.com";
        let tunnel_config = config.parse_ssh_tunnel_string(tunnel_str);
        assert!(tunnel_config.is_some());
        let tunnel_config = tunnel_config.unwrap();
        assert_eq!(tunnel_config.ssh_host, "host.example.com");
        assert_eq!(tunnel_config.ssh_port, 22);
        assert_eq!(tunnel_config.ssh_username, Some("user".to_string()));
        
        // Test with just host (no user)
        let tunnel_str = "host.example.com";
        let tunnel_config = config.parse_ssh_tunnel_string(tunnel_str);
        assert!(tunnel_config.is_some());
        let tunnel_config = tunnel_config.unwrap();
        assert_eq!(tunnel_config.ssh_host, "host.example.com");
        assert_eq!(tunnel_config.ssh_port, 22);
        assert!(tunnel_config.ssh_username.is_none());
    }
    
    #[test]
    fn test_connection_info_with_ssh_tunnel() {
        // Test that ConnectionInfo properly handles SSH tunnel configuration
        let connection_info = ConnectionInfo {
            database_type: DatabaseType::PostgreSQL,
            host: Some("db.internal.example.com".to_string()),
            port: Some(5432),
            username: Some("dbuser".to_string()),
            password: Some("dbpass".to_string()),
            database: Some("mydb".to_string()),
            file_path: None,
            options: HashMap::new(),
            docker_container: None,
        };
        
        // Verify connection info has required fields for SSH tunnel
        assert_eq!(connection_info.host, Some("db.internal.example.com".to_string()));
        assert_eq!(connection_info.port, Some(5432));
    }
}
